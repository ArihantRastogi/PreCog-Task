{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Classification\n",
    "- The task poses with the challenge to train a neural classifier to classify images into one of 100 predefined labels (selected from the dataset)\n",
    "- To do this, we will train a CNN (Convolutional Neural Network) on the different datasets generated and see how hyperparameter tuning affects its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "from random_word import RandomWords\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['routed', 'xylylene', 'snailfish', 'elohimic', 'tarpaulin', 'scalping', 'retinned', 'burglar', 'pacifical', 'carbamido', 'mayoress', 'unaisled', 'conubium', 'incurs', 'vaginitis', 'untrodden', 'tipmen', 'jewism', 'ferniest', 'socius', 'acned', 'calvarium', 'tursha', 'metheglin', 'excitate', 'ectopias', 'corone', 'sinful', 'bedazzled', 'aroxyl', 'sumpweeds', 'triage', 'tubbeck', 'quercetum', 'kicky', 'crucilly', 'occupant', 'wineglass', 'solfatara', 'meisje', 'augurous', 'amalgam', 'atnah', 'pallia', 'firth', 'dippier', 'glossata', 'purfles', 'exodus', 'brazilin', 'erbium', 'snoringly', 'curdly', 'scolders', 'salagrama', 'pythia', 'foliation', 'showyard', 'spatio', 'unfleece', 'anglings', 'cowpony', 'bedoyo', 'jitters', 'aliquant', 'pentosan', 'weldors', 'indazine', 'panderous', 'clarini', 'belauds', 'echoist', 'asthenic', 'utterance', 'orthocym', 'curse', 'stomached', 'diatomist', 'pines', 'thorter', 'cointreau', 'outrow', 'claybanks', 'mafura', 'leucaemic', 'wommera', 'vodkas', 'quota', 'marling', 'equaled', 'holiness', 'mucro', 'crampy', 'creeshes', 'tatsman', 'unpaised', 'hawkins', 'cocuisa', 'insanie', 'kultur']\n"
     ]
    }
   ],
   "source": [
    "# 100 random words for dataset\n",
    "def generate_random_words(num_words):\n",
    "    r = RandomWords()\n",
    "    words = []\n",
    "    while len(words) < num_words:\n",
    "        word = r.get_random_word()\n",
    "        if word and 5 <= len(word) <= 9:\n",
    "            words.append(word)\n",
    "\n",
    "    return words\n",
    "\n",
    "words = generate_random_words(100)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the easy set\n",
    "The basic features of this dataset include\n",
    "- Singular text font - OpenSans-Regular.ttf\n",
    "- The text color is fixed to be black and background to be white. (grayscale)\n",
    "- The text is not centered and is randomly positioned in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"content/dataset/easy\"):\n",
    "    shutil.rmtree(\"content/dataset/easy\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/easy\"):\n",
    "    os.makedirs(\"content/dataset/easy\")\n",
    "\n",
    "def generate_easy_set():\n",
    "    font_path = \"Fonts/OpenSans-Regular.ttf\"\n",
    "    if not os.path.exists(font_path):\n",
    "        raise FileNotFoundError(f\"Font file not found: {font_path}\")\n",
    "    output_dir = \"content/dataset/easy\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(0, 100):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            color = 255\n",
    "            image = Image.new(\"L\", (width, height), color)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            try:\n",
    "                font = ImageFont.truetype(font_path, 36)\n",
    "            except OSError as e:\n",
    "                print(f\"Error loading font: {e}\")\n",
    "                return\n",
    "            text = word.title()\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "            # random positioning\n",
    "            x = random.randint((width - text_width)//8, 7*((width - text_width)//8))\n",
    "            y = random.randint((height - text_height)//8, 7*((height - text_height)//8))\n",
    "            position = (x, y)\n",
    "            text_color = 0\n",
    "            draw.text(position, text, font=font, fill=text_color)\n",
    "            image.save(os.path.join(output_dir, f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_easy_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Formatting\n",
    "The class `WordImageDataset` has the following functionalities\n",
    "- Initialize Dataset: Reads image files from a directory and extracts unique words as class labels.\n",
    "- Create Label Mappings: Assigns each word a unique numerical index for classification.\n",
    "- Store Image Paths & Labels: Maintains a list of file paths and their corresponding labels.\n",
    "- Dataset Length (__len__): Returns the total number of images.\n",
    "- Load Image (__getitem__): Opens an image, converts it to grayscale, applies transformations (if any), and returns the image-label pair.\n",
    "\n",
    "Why This Approach?\n",
    "- Efficient Data Handling: Loads and preprocesses images dynamically rather than storing them all in memory.\n",
    "- Automated Labeling: Extracts labels from filenames, removing the need for manual annotation files.\n",
    "- Supports Transformations: Allows easy integration of resizing, normalization, and augmentations for better model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        self.idx_to_label = {}\n",
    "\n",
    "        # Get all unique words (labels)\n",
    "        words = set()\n",
    "        for filename in os.listdir(image_dir):\n",
    "            word = filename.split('_')[0]\n",
    "            words.add(word)\n",
    "\n",
    "        # Create label mappings\n",
    "        for idx, word in enumerate(sorted(words)):\n",
    "            self.label_to_idx[word] = idx\n",
    "            self.idx_to_label[idx] = word\n",
    "\n",
    "        # Load all images and labels\n",
    "        for filename in os.listdir(image_dir):\n",
    "            if filename.endswith('.png'):\n",
    "                word = filename.split('_')[0]\n",
    "                self.images.append(os.path.join(image_dir, filename))\n",
    "                self.labels.append(self.label_to_idx[word])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a basic CNN\n",
    "The model of choice is CNN, a Convolutional Neural Network, which is a standard architecture for image classification. CNNs are effective because they can automatically detect features like edges, textures, and patterns without requiring manual feature extraction.\n",
    "### Basic Architecture\n",
    "A typical CNN consists of the following layers:\n",
    "\n",
    "1. Convolutional Layer (Conv Layer)\n",
    "    - The core building block of a CNN, responsible for feature extraction.\n",
    "    - Uses a filter (kernel) that slides over the input image, detecting patterns like edges or textures.\n",
    "    - Output of this operation is called a feature map.\n",
    "    - `nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)`\n",
    "2. Activation Function (ReLU - Rectified Linear Unit)\n",
    "    - Applies a non-linearity to the feature maps, introducing the ability to learn complex patterns.\n",
    "    - Helps avoid the vanishing gradient problem.\n",
    "    - `nn.ReLU()` \n",
    "3. Pooling Layer (Max Pooling or Average Pooling)\n",
    "    - Reduces the spatial dimensions of feature maps while keeping important information.\n",
    "    - Helps make the model translation-invariant and improves computational efficiency.\n",
    "    - `nn.MaxPool2d(kernel_size, stride)`\n",
    "4. Fully Connected Layer (FC Layer)\n",
    "    - The final layers in a CNN, which convert the extracted features into predictions.\n",
    "    - Flattens the feature maps and passes them through dense layers.\n",
    "    - `nn.Linear(in_features, out_features)`\n",
    "\n",
    "Since the input images are of size 248*80 pixels, the below architecture seemed to work best along with introduction of `GradScaler`, `autocast` and `dropout`.\n",
    "\n",
    "1. GradScaler (`torch.amp.GradScaler()`)\n",
    "    - Purpose: Helps with mixed-precision training, which speeds up training and reduces memory usage.\n",
    "    - How?: It scales the loss value to prevent underflow when using half-precision (float16) computations.\n",
    "    - Benefit: Ensures stable updates to model weights while taking advantage of faster, lower-precision arithmetic.\n",
    "2. autocast (`torch.amp.autocast()`)\n",
    "    - Purpose: Dynamically switches between float16 and float32 precision during forward passes.\n",
    "    - How?: Uses float16 for less critical operations (e.g., matrix multiplications) and float32 for sensitive calculations (e.g., loss computation).\n",
    "    - Benefit: Improves computational efficiency while maintaining numerical stability.\n",
    "3. Dropout (`nn.Dropout()`)\n",
    "    - Purpose: Reduces overfitting by randomly setting some neuron activations to zero during training.\n",
    "    - How?: Each forward pass, a fraction of neurons is \"dropped out,\" forcing the model to learn more robust representations.\n",
    "    - Benefit: Increases generalization, preventing the model from memorizing specific training examples.\n",
    "\n",
    "For finding the best activation function and dropout value for model accuracy, the following `test_loop` was run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with Activation: ReLU, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.1850, Train Acc: 4.67%, Val Acc: 10.30%\n",
      "Epoch [2/20], Loss: 2.7701, Train Acc: 30.81%, Val Acc: 25.65%\n",
      "Epoch [3/20], Loss: 1.2739, Train Acc: 71.51%, Val Acc: 49.65%\n",
      "Epoch [4/20], Loss: 0.5504, Train Acc: 89.09%, Val Acc: 24.95%\n",
      "Epoch [5/20], Loss: 0.2674, Train Acc: 94.97%, Val Acc: 77.40%\n",
      "Epoch [6/20], Loss: 0.1346, Train Acc: 98.55%, Val Acc: 98.90%\n",
      "Epoch [7/20], Loss: 0.1098, Train Acc: 98.76%, Val Acc: 99.05%\n",
      "Epoch [8/20], Loss: 0.0993, Train Acc: 98.95%, Val Acc: 99.25%\n",
      "Epoch [9/20], Loss: 0.0828, Train Acc: 99.29%, Val Acc: 99.20%\n",
      "Epoch [10/20], Loss: 0.0783, Train Acc: 99.25%, Val Acc: 99.65%\n",
      "Epoch [11/20], Loss: 0.0742, Train Acc: 99.20%, Val Acc: 99.60%\n",
      "Epoch [12/20], Loss: 0.0705, Train Acc: 99.28%, Val Acc: 99.30%\n",
      "Epoch [13/20], Loss: 0.0674, Train Acc: 99.44%, Val Acc: 99.50%\n",
      "Epoch [14/20], Loss: 0.0680, Train Acc: 99.51%, Val Acc: 99.50%\n",
      "Epoch [15/20], Loss: 0.0638, Train Acc: 99.51%, Val Acc: 99.10%\n",
      "Epoch [16/20], Loss: 0.0632, Train Acc: 99.42%, Val Acc: 99.55%\n",
      "Epoch [17/20], Loss: 0.0672, Train Acc: 99.45%, Val Acc: 99.50%\n",
      "Epoch [18/20], Loss: 0.0643, Train Acc: 99.36%, Val Acc: 99.40%\n",
      "Epoch [19/20], Loss: 0.0656, Train Acc: 99.34%, Val Acc: 99.70%\n",
      "Epoch [20/20], Loss: 0.0669, Train Acc: 99.42%, Val Acc: 99.60%\n",
      "\n",
      "Testing with Activation: ReLU, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.2014, Train Acc: 4.20%, Val Acc: 10.10%\n",
      "Epoch [2/20], Loss: 2.7941, Train Acc: 30.18%, Val Acc: 30.80%\n",
      "Epoch [3/20], Loss: 1.5929, Train Acc: 59.74%, Val Acc: 74.55%\n",
      "Epoch [4/20], Loss: 0.8297, Train Acc: 81.25%, Val Acc: 85.10%\n",
      "Epoch [5/20], Loss: 0.4269, Train Acc: 91.24%, Val Acc: 94.80%\n",
      "Epoch [6/20], Loss: 0.2425, Train Acc: 96.25%, Val Acc: 97.80%\n",
      "Epoch [7/20], Loss: 0.1961, Train Acc: 97.09%, Val Acc: 97.95%\n",
      "Epoch [8/20], Loss: 0.1742, Train Acc: 97.49%, Val Acc: 98.20%\n",
      "Epoch [9/20], Loss: 0.1529, Train Acc: 97.91%, Val Acc: 98.85%\n",
      "Epoch [10/20], Loss: 0.1405, Train Acc: 98.36%, Val Acc: 99.05%\n",
      "Epoch [11/20], Loss: 0.1296, Train Acc: 98.39%, Val Acc: 99.05%\n",
      "Epoch [12/20], Loss: 0.1313, Train Acc: 98.16%, Val Acc: 99.25%\n",
      "Epoch [13/20], Loss: 0.1266, Train Acc: 98.33%, Val Acc: 98.60%\n",
      "Epoch [14/20], Loss: 0.1264, Train Acc: 98.29%, Val Acc: 98.90%\n",
      "Epoch [15/20], Loss: 0.1269, Train Acc: 98.38%, Val Acc: 99.20%\n",
      "Epoch [16/20], Loss: 0.1165, Train Acc: 98.64%, Val Acc: 98.85%\n",
      "Epoch [17/20], Loss: 0.1209, Train Acc: 98.67%, Val Acc: 99.00%\n",
      "Epoch [18/20], Loss: 0.1176, Train Acc: 98.62%, Val Acc: 99.10%\n",
      "Epoch [19/20], Loss: 0.1221, Train Acc: 98.44%, Val Acc: 99.45%\n",
      "Epoch [20/20], Loss: 0.1151, Train Acc: 98.62%, Val Acc: 99.05%\n",
      "\n",
      "Testing with Activation: ReLU, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.2673, Train Acc: 3.77%, Val Acc: 6.45%\n",
      "Epoch [2/20], Loss: 3.2370, Train Acc: 18.74%, Val Acc: 37.40%\n",
      "Epoch [3/20], Loss: 1.9497, Train Acc: 48.76%, Val Acc: 43.30%\n",
      "Epoch [4/20], Loss: 1.0869, Train Acc: 73.84%, Val Acc: 85.00%\n",
      "Epoch [5/20], Loss: 0.5566, Train Acc: 88.14%, Val Acc: 10.80%\n",
      "Epoch [6/20], Loss: 0.3417, Train Acc: 93.49%, Val Acc: 97.55%\n",
      "Epoch [7/20], Loss: 0.2845, Train Acc: 95.00%, Val Acc: 97.85%\n",
      "Epoch [8/20], Loss: 0.2597, Train Acc: 95.65%, Val Acc: 98.30%\n",
      "Epoch [9/20], Loss: 0.2351, Train Acc: 96.09%, Val Acc: 98.55%\n",
      "Epoch [10/20], Loss: 0.2159, Train Acc: 96.69%, Val Acc: 98.80%\n",
      "Epoch [11/20], Loss: 0.2023, Train Acc: 97.11%, Val Acc: 98.60%\n",
      "Epoch [12/20], Loss: 0.1952, Train Acc: 97.05%, Val Acc: 99.05%\n",
      "Epoch [13/20], Loss: 0.1815, Train Acc: 97.41%, Val Acc: 99.05%\n",
      "Epoch [14/20], Loss: 0.1776, Train Acc: 97.70%, Val Acc: 99.05%\n",
      "Epoch [15/20], Loss: 0.1813, Train Acc: 97.40%, Val Acc: 98.75%\n",
      "Epoch [16/20], Loss: 0.1907, Train Acc: 97.26%, Val Acc: 98.90%\n",
      "Epoch [17/20], Loss: 0.1837, Train Acc: 97.69%, Val Acc: 99.00%\n",
      "Epoch [18/20], Loss: 0.1800, Train Acc: 97.40%, Val Acc: 99.25%\n",
      "Epoch [19/20], Loss: 0.1790, Train Acc: 97.65%, Val Acc: 99.10%\n",
      "Epoch [20/20], Loss: 0.1775, Train Acc: 97.53%, Val Acc: 99.05%\n",
      "\n",
      "Testing with Activation: ReLU, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.3576, Train Acc: 3.40%, Val Acc: 8.25%\n",
      "Epoch [2/20], Loss: 3.3965, Train Acc: 15.56%, Val Acc: 17.20%\n",
      "Epoch [3/20], Loss: 2.2955, Train Acc: 38.60%, Val Acc: 51.75%\n",
      "Epoch [4/20], Loss: 1.5734, Train Acc: 56.86%, Val Acc: 50.85%\n",
      "Epoch [5/20], Loss: 1.0724, Train Acc: 72.06%, Val Acc: 23.60%\n",
      "Epoch [6/20], Loss: 0.6780, Train Acc: 85.06%, Val Acc: 94.95%\n",
      "Epoch [7/20], Loss: 0.5918, Train Acc: 87.99%, Val Acc: 95.75%\n",
      "Epoch [8/20], Loss: 0.5461, Train Acc: 88.94%, Val Acc: 94.20%\n",
      "Epoch [9/20], Loss: 0.4951, Train Acc: 90.19%, Val Acc: 96.85%\n",
      "Epoch [10/20], Loss: 0.4481, Train Acc: 91.55%, Val Acc: 97.15%\n",
      "Epoch [11/20], Loss: 0.4249, Train Acc: 91.92%, Val Acc: 97.50%\n",
      "Epoch [12/20], Loss: 0.4117, Train Acc: 92.50%, Val Acc: 97.75%\n",
      "Epoch [13/20], Loss: 0.4094, Train Acc: 92.47%, Val Acc: 97.55%\n",
      "Epoch [14/20], Loss: 0.4031, Train Acc: 92.60%, Val Acc: 97.55%\n",
      "Epoch [15/20], Loss: 0.3990, Train Acc: 92.79%, Val Acc: 97.65%\n",
      "Epoch [16/20], Loss: 0.3995, Train Acc: 92.69%, Val Acc: 97.70%\n",
      "Epoch [17/20], Loss: 0.3997, Train Acc: 92.83%, Val Acc: 97.80%\n",
      "Epoch [18/20], Loss: 0.4017, Train Acc: 92.74%, Val Acc: 97.85%\n",
      "Epoch [19/20], Loss: 0.3957, Train Acc: 92.84%, Val Acc: 98.10%\n",
      "Epoch [20/20], Loss: 0.4004, Train Acc: 92.79%, Val Acc: 97.80%\n",
      "\n",
      "Testing with Activation: Sigmoid, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.5355, Train Acc: 2.04%, Val Acc: 1.70%\n",
      "Epoch [2/20], Loss: 4.5050, Train Acc: 1.82%, Val Acc: 1.75%\n",
      "Epoch [3/20], Loss: 4.5508, Train Acc: 1.43%, Val Acc: 0.75%\n",
      "Epoch [4/20], Loss: 4.6062, Train Acc: 0.94%, Val Acc: 0.65%\n",
      "Epoch [5/20], Loss: 4.6063, Train Acc: 0.78%, Val Acc: 0.80%\n",
      "Epoch [6/20], Loss: 4.6042, Train Acc: 1.07%, Val Acc: 0.45%\n",
      "Epoch [7/20], Loss: 4.5954, Train Acc: 1.44%, Val Acc: 0.70%\n",
      "Epoch [8/20], Loss: 4.5749, Train Acc: 1.75%, Val Acc: 2.05%\n",
      "Epoch [9/20], Loss: 4.5367, Train Acc: 2.08%, Val Acc: 1.80%\n",
      "Epoch [10/20], Loss: 4.4865, Train Acc: 2.19%, Val Acc: 1.65%\n",
      "Epoch [11/20], Loss: 4.4623, Train Acc: 2.10%, Val Acc: 1.45%\n",
      "Epoch [12/20], Loss: 4.4585, Train Acc: 2.21%, Val Acc: 1.90%\n",
      "Epoch [13/20], Loss: 4.4558, Train Acc: 2.17%, Val Acc: 1.75%\n",
      "Epoch [14/20], Loss: 4.4530, Train Acc: 2.14%, Val Acc: 1.40%\n",
      "Epoch [15/20], Loss: 4.4481, Train Acc: 2.14%, Val Acc: 1.40%\n",
      "Epoch [16/20], Loss: 4.4475, Train Acc: 2.30%, Val Acc: 1.65%\n",
      "Epoch [17/20], Loss: 4.4470, Train Acc: 2.15%, Val Acc: 1.25%\n",
      "Epoch [18/20], Loss: 4.4471, Train Acc: 2.26%, Val Acc: 1.80%\n",
      "Epoch [19/20], Loss: 4.4463, Train Acc: 2.02%, Val Acc: 1.60%\n",
      "Epoch [20/20], Loss: 4.4456, Train Acc: 2.33%, Val Acc: 1.35%\n",
      "\n",
      "Testing with Activation: Sigmoid, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.5229, Train Acc: 1.96%, Val Acc: 1.90%\n",
      "Epoch [2/20], Loss: 4.3652, Train Acc: 2.14%, Val Acc: 1.75%\n",
      "Epoch [3/20], Loss: 4.2952, Train Acc: 2.14%, Val Acc: 1.00%\n",
      "Epoch [4/20], Loss: 4.3900, Train Acc: 1.96%, Val Acc: 1.10%\n",
      "Epoch [5/20], Loss: 4.4114, Train Acc: 1.75%, Val Acc: 1.00%\n",
      "Epoch [6/20], Loss: 4.3336, Train Acc: 1.88%, Val Acc: 1.15%\n",
      "Epoch [7/20], Loss: 4.3226, Train Acc: 1.82%, Val Acc: 1.15%\n",
      "Epoch [8/20], Loss: 4.3178, Train Acc: 1.88%, Val Acc: 1.45%\n",
      "Epoch [9/20], Loss: 4.2943, Train Acc: 2.04%, Val Acc: 2.30%\n",
      "Epoch [10/20], Loss: 4.2838, Train Acc: 1.98%, Val Acc: 1.50%\n",
      "Epoch [11/20], Loss: 4.2690, Train Acc: 2.33%, Val Acc: 1.45%\n",
      "Epoch [12/20], Loss: 4.2672, Train Acc: 1.99%, Val Acc: 1.55%\n",
      "Epoch [13/20], Loss: 4.2669, Train Acc: 2.17%, Val Acc: 1.50%\n",
      "Epoch [14/20], Loss: 4.2667, Train Acc: 2.17%, Val Acc: 1.55%\n",
      "Epoch [15/20], Loss: 4.2665, Train Acc: 2.06%, Val Acc: 1.65%\n",
      "Epoch [16/20], Loss: 4.2639, Train Acc: 2.23%, Val Acc: 1.65%\n",
      "Epoch [17/20], Loss: 4.2655, Train Acc: 2.05%, Val Acc: 1.40%\n",
      "Epoch [18/20], Loss: 4.2627, Train Acc: 1.86%, Val Acc: 1.65%\n",
      "Epoch [19/20], Loss: 4.2565, Train Acc: 2.04%, Val Acc: 1.85%\n",
      "Epoch [20/20], Loss: 4.2595, Train Acc: 2.11%, Val Acc: 1.40%\n",
      "\n",
      "Testing with Activation: Sigmoid, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.5342, Train Acc: 2.30%, Val Acc: 1.25%\n",
      "Epoch [2/20], Loss: 4.5087, Train Acc: 1.49%, Val Acc: 0.75%\n",
      "Epoch [3/20], Loss: 4.5918, Train Acc: 1.16%, Val Acc: 0.70%\n",
      "Epoch [4/20], Loss: 4.6064, Train Acc: 1.02%, Val Acc: 0.55%\n",
      "Epoch [5/20], Loss: 4.6062, Train Acc: 0.88%, Val Acc: 0.75%\n",
      "Epoch [6/20], Loss: 4.6044, Train Acc: 1.14%, Val Acc: 0.60%\n",
      "Epoch [7/20], Loss: 4.6038, Train Acc: 1.04%, Val Acc: 0.55%\n",
      "Epoch [8/20], Loss: 4.6043, Train Acc: 1.24%, Val Acc: 0.55%\n",
      "Epoch [9/20], Loss: 4.6043, Train Acc: 1.05%, Val Acc: 0.55%\n",
      "Epoch [10/20], Loss: 4.6019, Train Acc: 1.15%, Val Acc: 0.55%\n",
      "Epoch [11/20], Loss: 4.5953, Train Acc: 1.36%, Val Acc: 0.60%\n",
      "Epoch [12/20], Loss: 4.5929, Train Acc: 1.32%, Val Acc: 0.90%\n",
      "Epoch [13/20], Loss: 4.5913, Train Acc: 1.52%, Val Acc: 0.95%\n",
      "Epoch [14/20], Loss: 4.5892, Train Acc: 1.52%, Val Acc: 1.05%\n",
      "Epoch [15/20], Loss: 4.5867, Train Acc: 1.56%, Val Acc: 1.20%\n",
      "Epoch [16/20], Loss: 4.5867, Train Acc: 1.56%, Val Acc: 1.00%\n",
      "Epoch [17/20], Loss: 4.5857, Train Acc: 1.64%, Val Acc: 1.10%\n",
      "Epoch [18/20], Loss: 4.5860, Train Acc: 1.91%, Val Acc: 1.00%\n",
      "Epoch [19/20], Loss: 4.5853, Train Acc: 1.75%, Val Acc: 1.15%\n",
      "Epoch [20/20], Loss: 4.5850, Train Acc: 1.71%, Val Acc: 1.05%\n",
      "\n",
      "Testing with Activation: Sigmoid, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.6261, Train Acc: 1.29%, Val Acc: 1.30%\n",
      "Epoch [2/20], Loss: 4.5595, Train Acc: 1.41%, Val Acc: 1.05%\n",
      "Epoch [3/20], Loss: 4.5958, Train Acc: 1.16%, Val Acc: 0.45%\n",
      "Epoch [4/20], Loss: 4.6057, Train Acc: 1.06%, Val Acc: 0.45%\n",
      "Epoch [5/20], Loss: 4.6065, Train Acc: 1.07%, Val Acc: 0.60%\n",
      "Epoch [6/20], Loss: 4.6044, Train Acc: 1.04%, Val Acc: 0.45%\n",
      "Epoch [7/20], Loss: 4.6043, Train Acc: 1.02%, Val Acc: 0.45%\n",
      "Epoch [8/20], Loss: 4.6041, Train Acc: 1.14%, Val Acc: 0.45%\n",
      "Epoch [9/20], Loss: 4.6041, Train Acc: 1.02%, Val Acc: 0.65%\n",
      "Epoch [10/20], Loss: 4.6003, Train Acc: 1.16%, Val Acc: 1.05%\n",
      "Epoch [11/20], Loss: 4.5945, Train Acc: 1.65%, Val Acc: 1.85%\n",
      "Epoch [12/20], Loss: 4.5932, Train Acc: 1.75%, Val Acc: 1.80%\n",
      "Epoch [13/20], Loss: 4.5924, Train Acc: 1.52%, Val Acc: 1.85%\n",
      "Epoch [14/20], Loss: 4.5914, Train Acc: 1.77%, Val Acc: 2.00%\n",
      "Epoch [15/20], Loss: 4.5909, Train Acc: 1.46%, Val Acc: 1.25%\n",
      "Epoch [16/20], Loss: 4.5902, Train Acc: 1.77%, Val Acc: 1.95%\n",
      "Epoch [17/20], Loss: 4.5905, Train Acc: 1.73%, Val Acc: 1.95%\n",
      "Epoch [18/20], Loss: 4.5908, Train Acc: 1.62%, Val Acc: 2.25%\n",
      "Epoch [19/20], Loss: 4.5900, Train Acc: 1.64%, Val Acc: 1.75%\n",
      "Epoch [20/20], Loss: 4.5908, Train Acc: 1.65%, Val Acc: 1.95%\n",
      "\n",
      "Testing with Activation: Tanh, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.6223, Train Acc: 1.86%, Val Acc: 1.85%\n",
      "Epoch [2/20], Loss: 4.4591, Train Acc: 2.70%, Val Acc: 3.00%\n",
      "Epoch [3/20], Loss: 4.2278, Train Acc: 3.06%, Val Acc: 3.20%\n",
      "Epoch [4/20], Loss: 4.1169, Train Acc: 3.46%, Val Acc: 3.15%\n",
      "Epoch [5/20], Loss: 4.0458, Train Acc: 4.33%, Val Acc: 4.45%\n",
      "Epoch [6/20], Loss: 3.9322, Train Acc: 5.38%, Val Acc: 5.75%\n",
      "Epoch [7/20], Loss: 3.8543, Train Acc: 5.26%, Val Acc: 6.00%\n",
      "Epoch [8/20], Loss: 3.7993, Train Acc: 5.67%, Val Acc: 6.35%\n",
      "Epoch [9/20], Loss: 3.7547, Train Acc: 5.92%, Val Acc: 5.45%\n",
      "Epoch [10/20], Loss: 3.7193, Train Acc: 6.72%, Val Acc: 6.60%\n",
      "Epoch [11/20], Loss: 3.6869, Train Acc: 6.90%, Val Acc: 7.50%\n",
      "Epoch [12/20], Loss: 3.6814, Train Acc: 7.19%, Val Acc: 7.10%\n",
      "Epoch [13/20], Loss: 3.6798, Train Acc: 7.35%, Val Acc: 7.65%\n",
      "Epoch [14/20], Loss: 3.6751, Train Acc: 7.10%, Val Acc: 8.30%\n",
      "Epoch [15/20], Loss: 3.6729, Train Acc: 7.08%, Val Acc: 7.55%\n",
      "Epoch [16/20], Loss: 3.6572, Train Acc: 7.45%, Val Acc: 7.20%\n",
      "Epoch [17/20], Loss: 3.6597, Train Acc: 7.19%, Val Acc: 7.75%\n",
      "Epoch [18/20], Loss: 3.6628, Train Acc: 7.35%, Val Acc: 7.20%\n",
      "Epoch [19/20], Loss: 3.6668, Train Acc: 7.17%, Val Acc: 7.20%\n",
      "Epoch [20/20], Loss: 3.6654, Train Acc: 7.60%, Val Acc: 7.95%\n",
      "\n",
      "Testing with Activation: Tanh, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.6234, Train Acc: 1.84%, Val Acc: 3.15%\n",
      "Epoch [2/20], Loss: 4.3926, Train Acc: 2.81%, Val Acc: 2.25%\n",
      "Epoch [3/20], Loss: 4.2341, Train Acc: 3.11%, Val Acc: 3.05%\n",
      "Epoch [4/20], Loss: 4.1090, Train Acc: 3.79%, Val Acc: 1.40%\n",
      "Epoch [5/20], Loss: 3.9805, Train Acc: 4.46%, Val Acc: 1.60%\n",
      "Epoch [6/20], Loss: 3.8623, Train Acc: 5.44%, Val Acc: 3.45%\n",
      "Epoch [7/20], Loss: 3.7955, Train Acc: 5.66%, Val Acc: 4.75%\n",
      "Epoch [8/20], Loss: 3.7420, Train Acc: 6.56%, Val Acc: 6.55%\n",
      "Epoch [9/20], Loss: 3.7133, Train Acc: 6.61%, Val Acc: 6.20%\n",
      "Epoch [10/20], Loss: 3.6676, Train Acc: 6.96%, Val Acc: 7.15%\n",
      "Epoch [11/20], Loss: 3.6417, Train Acc: 7.15%, Val Acc: 7.45%\n",
      "Epoch [12/20], Loss: 3.6378, Train Acc: 7.19%, Val Acc: 7.50%\n",
      "Epoch [13/20], Loss: 3.6341, Train Acc: 7.34%, Val Acc: 7.80%\n",
      "Epoch [14/20], Loss: 3.6273, Train Acc: 7.74%, Val Acc: 7.65%\n",
      "Epoch [15/20], Loss: 3.6215, Train Acc: 7.22%, Val Acc: 7.35%\n",
      "Epoch [16/20], Loss: 3.6132, Train Acc: 7.61%, Val Acc: 8.00%\n",
      "Epoch [17/20], Loss: 3.6196, Train Acc: 7.46%, Val Acc: 7.85%\n",
      "Epoch [18/20], Loss: 3.6198, Train Acc: 7.45%, Val Acc: 7.45%\n",
      "Epoch [19/20], Loss: 3.6143, Train Acc: 6.92%, Val Acc: 8.10%\n",
      "Epoch [20/20], Loss: 3.6181, Train Acc: 7.41%, Val Acc: 7.55%\n",
      "\n",
      "Testing with Activation: Tanh, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.6673, Train Acc: 1.51%, Val Acc: 1.55%\n",
      "Epoch [2/20], Loss: 4.5188, Train Acc: 1.90%, Val Acc: 1.35%\n",
      "Epoch [3/20], Loss: 4.3563, Train Acc: 2.75%, Val Acc: 0.90%\n",
      "Epoch [4/20], Loss: 4.2411, Train Acc: 3.35%, Val Acc: 1.05%\n",
      "Epoch [5/20], Loss: 4.1472, Train Acc: 3.64%, Val Acc: 1.95%\n",
      "Epoch [6/20], Loss: 3.9974, Train Acc: 4.15%, Val Acc: 6.05%\n",
      "Epoch [7/20], Loss: 3.9371, Train Acc: 4.81%, Val Acc: 5.25%\n",
      "Epoch [8/20], Loss: 3.8829, Train Acc: 5.81%, Val Acc: 3.15%\n",
      "Epoch [9/20], Loss: 3.8503, Train Acc: 5.76%, Val Acc: 2.90%\n",
      "Epoch [10/20], Loss: 3.7949, Train Acc: 5.99%, Val Acc: 7.45%\n",
      "Epoch [11/20], Loss: 3.7648, Train Acc: 6.04%, Val Acc: 7.45%\n",
      "Epoch [12/20], Loss: 3.7600, Train Acc: 6.39%, Val Acc: 7.40%\n",
      "Epoch [13/20], Loss: 3.7606, Train Acc: 6.16%, Val Acc: 8.95%\n",
      "Epoch [14/20], Loss: 3.7517, Train Acc: 6.56%, Val Acc: 6.75%\n",
      "Epoch [15/20], Loss: 3.7340, Train Acc: 6.84%, Val Acc: 7.15%\n",
      "Epoch [16/20], Loss: 3.7371, Train Acc: 6.67%, Val Acc: 8.10%\n",
      "Epoch [17/20], Loss: 3.7293, Train Acc: 7.05%, Val Acc: 7.80%\n",
      "Epoch [18/20], Loss: 3.7333, Train Acc: 6.74%, Val Acc: 6.80%\n",
      "Epoch [19/20], Loss: 3.7347, Train Acc: 6.49%, Val Acc: 8.90%\n",
      "Epoch [20/20], Loss: 3.7289, Train Acc: 6.50%, Val Acc: 7.00%\n",
      "\n",
      "Testing with Activation: Tanh, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.6629, Train Acc: 1.52%, Val Acc: 2.50%\n",
      "Epoch [2/20], Loss: 4.4917, Train Acc: 2.34%, Val Acc: 2.90%\n",
      "Epoch [3/20], Loss: 4.3355, Train Acc: 2.85%, Val Acc: 1.70%\n",
      "Epoch [4/20], Loss: 4.2152, Train Acc: 3.09%, Val Acc: 3.10%\n",
      "Epoch [5/20], Loss: 4.1138, Train Acc: 3.69%, Val Acc: 1.60%\n",
      "Epoch [6/20], Loss: 4.0163, Train Acc: 4.24%, Val Acc: 4.55%\n",
      "Epoch [7/20], Loss: 3.9453, Train Acc: 4.39%, Val Acc: 4.45%\n",
      "Epoch [8/20], Loss: 3.8996, Train Acc: 5.35%, Val Acc: 3.40%\n",
      "Epoch [9/20], Loss: 3.8676, Train Acc: 5.09%, Val Acc: 3.15%\n",
      "Epoch [10/20], Loss: 3.8231, Train Acc: 5.64%, Val Acc: 5.75%\n",
      "Epoch [11/20], Loss: 3.8012, Train Acc: 6.08%, Val Acc: 6.65%\n",
      "Epoch [12/20], Loss: 3.7947, Train Acc: 6.04%, Val Acc: 6.90%\n",
      "Epoch [13/20], Loss: 3.7836, Train Acc: 6.06%, Val Acc: 6.25%\n",
      "Epoch [14/20], Loss: 3.7784, Train Acc: 6.16%, Val Acc: 6.85%\n",
      "Epoch [15/20], Loss: 3.7762, Train Acc: 6.09%, Val Acc: 6.35%\n",
      "Epoch [16/20], Loss: 3.7794, Train Acc: 5.66%, Val Acc: 7.05%\n",
      "Epoch [17/20], Loss: 3.7793, Train Acc: 6.12%, Val Acc: 6.25%\n",
      "Epoch [18/20], Loss: 3.7726, Train Acc: 5.99%, Val Acc: 6.85%\n",
      "Epoch [19/20], Loss: 3.7708, Train Acc: 5.64%, Val Acc: 7.30%\n",
      "Epoch [20/20], Loss: 3.7674, Train Acc: 6.39%, Val Acc: 6.95%\n",
      "\n",
      "Test Results:\n",
      "Activation: ReLU, Dropout: 0.2, Best Val Acc: 99.70%\n",
      "Activation: ReLU, Dropout: 0.3, Best Val Acc: 99.45%\n",
      "Activation: ReLU, Dropout: 0.4, Best Val Acc: 99.25%\n",
      "Activation: ReLU, Dropout: 0.5, Best Val Acc: 98.10%\n",
      "Activation: Sigmoid, Dropout: 0.2, Best Val Acc: 2.05%\n",
      "Activation: Sigmoid, Dropout: 0.3, Best Val Acc: 2.30%\n",
      "Activation: Sigmoid, Dropout: 0.4, Best Val Acc: 1.25%\n",
      "Activation: Sigmoid, Dropout: 0.5, Best Val Acc: 2.25%\n",
      "Activation: Tanh, Dropout: 0.2, Best Val Acc: 8.30%\n",
      "Activation: Tanh, Dropout: 0.3, Best Val Acc: 8.10%\n",
      "Activation: Tanh, Dropout: 0.4, Best Val Acc: 8.95%\n",
      "Activation: Tanh, Dropout: 0.5, Best Val Acc: 7.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "def test_loop():\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    dataset = WordImageDataset('content/dataset/easy', transform=transform)\n",
    "\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(dataset)), test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    activation_fns = {\n",
    "        'ReLU': nn.ReLU(),\n",
    "        'Sigmoid': nn.Sigmoid(),\n",
    "        'Tanh': nn.Tanh()\n",
    "    }\n",
    "    dropout_rates = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "    results = {}\n",
    "    for activation_name, activation_fn in activation_fns.items():\n",
    "        for dropout_rate in dropout_rates:\n",
    "            print(f\"\\nTesting with Activation: {activation_name}, Dropout: {dropout_rate}\")\n",
    "            model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=activation_fn, dropout_rate=dropout_rate).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "            scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "            best_val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "            results[(activation_name, dropout_rate)] = best_val_acc\n",
    "\n",
    "    print(\"\\nTest Results:\")\n",
    "    for (activation_name, dropout_rate), val_acc in results.items():\n",
    "        print(f\"Activation: {activation_name}, Dropout: {dropout_rate}, Best Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Activation: ReLU, Dropout: 0.2, Best Val Acc: 99.70%`\n",
    "- ReLU seems to be the best activation function for the model and lower dropout is giving a better result. \n",
    "- Let's test this hypothesis of low dropout rate along with other parameters and check if the model is not being overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.3267, Train Acc: 3.79%, Val Acc: 1.85%\n",
      "Epoch [2/20], Loss: 3.1960, Train Acc: 20.66%, Val Acc: 32.63%\n",
      "Epoch [3/20], Loss: 1.8247, Train Acc: 54.11%, Val Acc: 27.99%\n",
      "Epoch [4/20], Loss: 0.9639, Train Acc: 78.34%, Val Acc: 51.22%\n",
      "Epoch [5/20], Loss: 0.5038, Train Acc: 89.47%, Val Acc: 75.86%\n",
      "Epoch [6/20], Loss: 0.2713, Train Acc: 95.43%, Val Acc: 97.40%\n",
      "Epoch [7/20], Loss: 0.2169, Train Acc: 97.07%, Val Acc: 97.85%\n",
      "Epoch [8/20], Loss: 0.1873, Train Acc: 97.66%, Val Acc: 97.60%\n",
      "Epoch [9/20], Loss: 0.1670, Train Acc: 98.16%, Val Acc: 98.80%\n",
      "Epoch [10/20], Loss: 0.1520, Train Acc: 98.37%, Val Acc: 98.70%\n",
      "Epoch [11/20], Loss: 0.1380, Train Acc: 98.53%, Val Acc: 98.85%\n",
      "Epoch [12/20], Loss: 0.1365, Train Acc: 98.37%, Val Acc: 98.60%\n",
      "Epoch [13/20], Loss: 0.1376, Train Acc: 98.49%, Val Acc: 99.10%\n",
      "Epoch [14/20], Loss: 0.1302, Train Acc: 98.71%, Val Acc: 99.05%\n",
      "Epoch [15/20], Loss: 0.1292, Train Acc: 98.63%, Val Acc: 99.00%\n",
      "Epoch [16/20], Loss: 0.1236, Train Acc: 98.86%, Val Acc: 99.20%\n",
      "Epoch [17/20], Loss: 0.1295, Train Acc: 98.51%, Val Acc: 98.90%\n",
      "Epoch [18/20], Loss: 0.1236, Train Acc: 98.86%, Val Acc: 99.25%\n",
      "Epoch [19/20], Loss: 0.1363, Train Acc: 98.40%, Val Acc: 98.95%\n",
      "Epoch [20/20], Loss: 0.1271, Train Acc: 98.51%, Val Acc: 99.10%\n",
      "\n",
      "Testing with Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.2752, Train Acc: 4.13%, Val Acc: 3.60%\n",
      "Epoch [2/20], Loss: 2.9110, Train Acc: 26.85%, Val Acc: 33.38%\n",
      "Epoch [3/20], Loss: 1.6482, Train Acc: 59.08%, Val Acc: 20.59%\n",
      "Epoch [4/20], Loss: 0.8796, Train Acc: 80.41%, Val Acc: 67.62%\n",
      "Epoch [5/20], Loss: 0.4846, Train Acc: 89.77%, Val Acc: 86.96%\n",
      "Epoch [6/20], Loss: 0.2759, Train Acc: 95.89%, Val Acc: 96.45%\n",
      "Epoch [7/20], Loss: 0.2359, Train Acc: 96.40%, Val Acc: 98.10%\n",
      "Epoch [8/20], Loss: 0.1952, Train Acc: 97.50%, Val Acc: 98.85%\n",
      "Epoch [9/20], Loss: 0.1775, Train Acc: 97.70%, Val Acc: 98.90%\n",
      "Epoch [10/20], Loss: 0.1572, Train Acc: 98.21%, Val Acc: 98.85%\n",
      "Epoch [11/20], Loss: 0.1433, Train Acc: 98.44%, Val Acc: 99.10%\n",
      "Epoch [12/20], Loss: 0.1396, Train Acc: 98.57%, Val Acc: 99.55%\n",
      "Epoch [13/20], Loss: 0.1432, Train Acc: 98.27%, Val Acc: 99.25%\n",
      "Epoch [14/20], Loss: 0.1439, Train Acc: 98.21%, Val Acc: 98.95%\n",
      "Epoch [15/20], Loss: 0.1378, Train Acc: 98.59%, Val Acc: 99.30%\n",
      "Epoch [16/20], Loss: 0.1334, Train Acc: 98.74%, Val Acc: 99.10%\n",
      "Epoch [17/20], Loss: 0.1337, Train Acc: 98.66%, Val Acc: 98.85%\n",
      "Epoch [18/20], Loss: 0.1342, Train Acc: 98.44%, Val Acc: 99.15%\n",
      "Epoch [19/20], Loss: 0.1338, Train Acc: 98.66%, Val Acc: 99.10%\n",
      "Epoch [20/20], Loss: 0.1397, Train Acc: 98.49%, Val Acc: 99.30%\n",
      "\n",
      "Testing with Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.3242, Train Acc: 3.44%, Val Acc: 5.80%\n",
      "Epoch [2/20], Loss: 3.3288, Train Acc: 18.30%, Val Acc: 3.95%\n",
      "Epoch [3/20], Loss: 1.8542, Train Acc: 54.72%, Val Acc: 41.93%\n",
      "Epoch [4/20], Loss: 1.0577, Train Acc: 75.63%, Val Acc: 48.13%\n",
      "Epoch [5/20], Loss: 0.6695, Train Acc: 84.90%, Val Acc: 76.31%\n",
      "Epoch [6/20], Loss: 0.4219, Train Acc: 91.97%, Val Acc: 96.85%\n",
      "Epoch [7/20], Loss: 0.3583, Train Acc: 93.74%, Val Acc: 98.25%\n",
      "Epoch [8/20], Loss: 0.3199, Train Acc: 94.88%, Val Acc: 98.55%\n",
      "Epoch [9/20], Loss: 0.2905, Train Acc: 95.43%, Val Acc: 98.45%\n",
      "Epoch [10/20], Loss: 0.2596, Train Acc: 95.77%, Val Acc: 98.00%\n",
      "Epoch [11/20], Loss: 0.2509, Train Acc: 96.60%, Val Acc: 98.35%\n",
      "Epoch [12/20], Loss: 0.2420, Train Acc: 96.60%, Val Acc: 98.90%\n",
      "Epoch [13/20], Loss: 0.2296, Train Acc: 96.93%, Val Acc: 98.70%\n",
      "Epoch [14/20], Loss: 0.2286, Train Acc: 96.96%, Val Acc: 98.85%\n",
      "Epoch [15/20], Loss: 0.2267, Train Acc: 96.67%, Val Acc: 99.05%\n",
      "Epoch [16/20], Loss: 0.2284, Train Acc: 96.99%, Val Acc: 99.00%\n",
      "Epoch [17/20], Loss: 0.2301, Train Acc: 96.81%, Val Acc: 98.90%\n",
      "Epoch [18/20], Loss: 0.2248, Train Acc: 96.99%, Val Acc: 99.05%\n",
      "Epoch [19/20], Loss: 0.2264, Train Acc: 97.01%, Val Acc: 99.10%\n",
      "Epoch [20/20], Loss: 0.2297, Train Acc: 96.57%, Val Acc: 99.00%\n",
      "\n",
      "Testing with Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.3680, Train Acc: 3.20%, Val Acc: 4.95%\n",
      "Epoch [2/20], Loss: 3.7918, Train Acc: 8.20%, Val Acc: 7.50%\n",
      "Epoch [3/20], Loss: 3.0072, Train Acc: 22.80%, Val Acc: 29.39%\n",
      "Epoch [4/20], Loss: 2.1175, Train Acc: 43.79%, Val Acc: 48.13%\n",
      "Epoch [5/20], Loss: 1.7074, Train Acc: 53.08%, Val Acc: 46.88%\n",
      "Epoch [6/20], Loss: 1.3261, Train Acc: 65.30%, Val Acc: 72.41%\n",
      "Epoch [7/20], Loss: 1.2083, Train Acc: 69.42%, Val Acc: 87.21%\n",
      "Epoch [8/20], Loss: 1.1427, Train Acc: 72.51%, Val Acc: 76.91%\n",
      "Epoch [9/20], Loss: 1.0857, Train Acc: 74.01%, Val Acc: 87.71%\n",
      "Epoch [10/20], Loss: 1.0304, Train Acc: 75.31%, Val Acc: 89.26%\n",
      "Epoch [11/20], Loss: 0.9974, Train Acc: 76.30%, Val Acc: 89.36%\n",
      "Epoch [12/20], Loss: 0.9681, Train Acc: 77.80%, Val Acc: 89.21%\n",
      "Epoch [13/20], Loss: 0.9829, Train Acc: 76.81%, Val Acc: 90.00%\n",
      "Epoch [14/20], Loss: 0.9900, Train Acc: 76.63%, Val Acc: 90.55%\n",
      "Epoch [15/20], Loss: 0.9636, Train Acc: 77.35%, Val Acc: 90.55%\n",
      "Epoch [16/20], Loss: 0.9442, Train Acc: 78.80%, Val Acc: 90.65%\n",
      "Epoch [17/20], Loss: 0.9647, Train Acc: 77.35%, Val Acc: 90.30%\n",
      "Epoch [18/20], Loss: 0.9395, Train Acc: 77.98%, Val Acc: 90.45%\n",
      "Epoch [19/20], Loss: 0.9482, Train Acc: 78.21%, Val Acc: 90.20%\n",
      "Epoch [20/20], Loss: 0.9471, Train Acc: 78.13%, Val Acc: 90.40%\n",
      "\n",
      "Testing with Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.3189, Train Acc: 3.34%, Val Acc: 7.40%\n",
      "Epoch [2/20], Loss: 3.3412, Train Acc: 17.23%, Val Acc: 12.33%\n",
      "Epoch [3/20], Loss: 1.9714, Train Acc: 50.74%, Val Acc: 36.47%\n",
      "Epoch [4/20], Loss: 1.0812, Train Acc: 74.83%, Val Acc: 84.07%\n",
      "Epoch [5/20], Loss: 0.5749, Train Acc: 88.09%, Val Acc: 62.80%\n",
      "Epoch [6/20], Loss: 0.3005, Train Acc: 95.49%, Val Acc: 97.60%\n",
      "Epoch [7/20], Loss: 0.2398, Train Acc: 96.99%, Val Acc: 98.20%\n",
      "Epoch [8/20], Loss: 0.2098, Train Acc: 97.64%, Val Acc: 97.80%\n",
      "Epoch [9/20], Loss: 0.1806, Train Acc: 98.10%, Val Acc: 98.67%\n",
      "Epoch [10/20], Loss: 0.1659, Train Acc: 98.34%, Val Acc: 98.60%\n",
      "Epoch [11/20], Loss: 0.1490, Train Acc: 98.46%, Val Acc: 98.60%\n",
      "Epoch [12/20], Loss: 0.1438, Train Acc: 98.70%, Val Acc: 99.47%\n",
      "Epoch [13/20], Loss: 0.1404, Train Acc: 98.83%, Val Acc: 99.27%\n",
      "Epoch [14/20], Loss: 0.1449, Train Acc: 98.54%, Val Acc: 99.33%\n",
      "Epoch [15/20], Loss: 0.1389, Train Acc: 98.71%, Val Acc: 99.00%\n",
      "Epoch [16/20], Loss: 0.1399, Train Acc: 98.66%, Val Acc: 99.07%\n",
      "Epoch [17/20], Loss: 0.1346, Train Acc: 98.94%, Val Acc: 99.00%\n",
      "Epoch [18/20], Loss: 0.1330, Train Acc: 98.91%, Val Acc: 98.80%\n",
      "Epoch [19/20], Loss: 0.1362, Train Acc: 98.76%, Val Acc: 99.07%\n",
      "Epoch [20/20], Loss: 0.1398, Train Acc: 98.69%, Val Acc: 99.00%\n",
      "\n",
      "Testing with Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.2979, Train Acc: 3.49%, Val Acc: 3.73%\n",
      "Epoch [2/20], Loss: 3.3460, Train Acc: 17.11%, Val Acc: 5.40%\n",
      "Epoch [3/20], Loss: 1.8458, Train Acc: 55.86%, Val Acc: 59.27%\n",
      "Epoch [4/20], Loss: 0.9287, Train Acc: 80.07%, Val Acc: 49.67%\n",
      "Epoch [5/20], Loss: 0.4995, Train Acc: 90.43%, Val Acc: 74.07%\n",
      "Epoch [6/20], Loss: 0.2821, Train Acc: 95.37%, Val Acc: 98.07%\n",
      "Epoch [7/20], Loss: 0.2285, Train Acc: 96.93%, Val Acc: 97.20%\n",
      "Epoch [8/20], Loss: 0.2046, Train Acc: 97.44%, Val Acc: 97.67%\n",
      "Epoch [9/20], Loss: 0.1900, Train Acc: 97.50%, Val Acc: 99.00%\n",
      "Epoch [10/20], Loss: 0.1673, Train Acc: 98.10%, Val Acc: 98.80%\n",
      "Epoch [11/20], Loss: 0.1539, Train Acc: 98.19%, Val Acc: 98.47%\n",
      "Epoch [12/20], Loss: 0.1523, Train Acc: 98.36%, Val Acc: 98.80%\n",
      "Epoch [13/20], Loss: 0.1513, Train Acc: 98.27%, Val Acc: 98.93%\n",
      "Epoch [14/20], Loss: 0.1427, Train Acc: 98.47%, Val Acc: 99.27%\n",
      "Epoch [15/20], Loss: 0.1380, Train Acc: 98.79%, Val Acc: 99.20%\n",
      "Epoch [16/20], Loss: 0.1433, Train Acc: 98.43%, Val Acc: 99.40%\n",
      "Epoch [17/20], Loss: 0.1453, Train Acc: 98.39%, Val Acc: 99.27%\n",
      "Epoch [18/20], Loss: 0.1461, Train Acc: 98.43%, Val Acc: 99.20%\n",
      "Epoch [19/20], Loss: 0.1387, Train Acc: 98.69%, Val Acc: 99.07%\n",
      "Epoch [20/20], Loss: 0.1378, Train Acc: 98.51%, Val Acc: 98.93%\n",
      "\n",
      "Testing with Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.3434, Train Acc: 3.06%, Val Acc: 4.40%\n",
      "Epoch [2/20], Loss: 3.7493, Train Acc: 8.67%, Val Acc: 15.87%\n",
      "Epoch [3/20], Loss: 2.7725, Train Acc: 28.34%, Val Acc: 8.67%\n",
      "Epoch [4/20], Loss: 1.8479, Train Acc: 51.89%, Val Acc: 41.33%\n",
      "Epoch [5/20], Loss: 1.2332, Train Acc: 68.53%, Val Acc: 41.07%\n",
      "Epoch [6/20], Loss: 0.8428, Train Acc: 81.10%, Val Acc: 89.67%\n",
      "Epoch [7/20], Loss: 0.7062, Train Acc: 85.90%, Val Acc: 94.13%\n",
      "Epoch [8/20], Loss: 0.6518, Train Acc: 87.11%, Val Acc: 93.47%\n",
      "Epoch [9/20], Loss: 0.6011, Train Acc: 88.37%, Val Acc: 94.93%\n",
      "Epoch [10/20], Loss: 0.5652, Train Acc: 89.04%, Val Acc: 94.93%\n",
      "Epoch [11/20], Loss: 0.5310, Train Acc: 90.40%, Val Acc: 95.40%\n",
      "Epoch [12/20], Loss: 0.5252, Train Acc: 90.79%, Val Acc: 96.20%\n",
      "Epoch [13/20], Loss: 0.5110, Train Acc: 90.93%, Val Acc: 96.00%\n",
      "Epoch [14/20], Loss: 0.5031, Train Acc: 91.19%, Val Acc: 96.27%\n",
      "Epoch [15/20], Loss: 0.4980, Train Acc: 91.44%, Val Acc: 95.73%\n",
      "Epoch [16/20], Loss: 0.4959, Train Acc: 91.31%, Val Acc: 97.13%\n",
      "Epoch [17/20], Loss: 0.5070, Train Acc: 90.87%, Val Acc: 96.47%\n",
      "Epoch [18/20], Loss: 0.4930, Train Acc: 91.34%, Val Acc: 95.20%\n",
      "Epoch [19/20], Loss: 0.4948, Train Acc: 91.37%, Val Acc: 96.27%\n",
      "Epoch [20/20], Loss: 0.5027, Train Acc: 91.09%, Val Acc: 96.60%\n",
      "\n",
      "Testing with Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.3965, Train Acc: 2.93%, Val Acc: 4.27%\n",
      "Epoch [2/20], Loss: 3.7629, Train Acc: 9.16%, Val Acc: 18.20%\n",
      "Epoch [3/20], Loss: 2.7102, Train Acc: 30.34%, Val Acc: 33.13%\n",
      "Epoch [4/20], Loss: 1.7880, Train Acc: 53.76%, Val Acc: 64.27%\n",
      "Epoch [5/20], Loss: 1.1576, Train Acc: 70.89%, Val Acc: 49.13%\n",
      "Epoch [6/20], Loss: 0.7858, Train Acc: 83.03%, Val Acc: 93.53%\n",
      "Epoch [7/20], Loss: 0.6759, Train Acc: 86.00%, Val Acc: 93.73%\n",
      "Epoch [8/20], Loss: 0.6193, Train Acc: 88.11%, Val Acc: 94.20%\n",
      "Epoch [9/20], Loss: 0.5764, Train Acc: 88.71%, Val Acc: 96.20%\n",
      "Epoch [10/20], Loss: 0.5414, Train Acc: 89.41%, Val Acc: 96.00%\n",
      "Epoch [11/20], Loss: 0.5007, Train Acc: 90.61%, Val Acc: 97.00%\n",
      "Epoch [12/20], Loss: 0.5055, Train Acc: 90.44%, Val Acc: 97.27%\n",
      "Epoch [13/20], Loss: 0.4941, Train Acc: 90.77%, Val Acc: 96.73%\n",
      "Epoch [14/20], Loss: 0.4874, Train Acc: 91.24%, Val Acc: 97.33%\n",
      "Epoch [15/20], Loss: 0.4985, Train Acc: 91.01%, Val Acc: 96.07%\n",
      "Epoch [16/20], Loss: 0.4936, Train Acc: 90.73%, Val Acc: 96.87%\n",
      "Epoch [17/20], Loss: 0.4785, Train Acc: 91.56%, Val Acc: 96.87%\n",
      "Epoch [18/20], Loss: 0.4847, Train Acc: 90.97%, Val Acc: 97.47%\n",
      "Epoch [19/20], Loss: 0.4715, Train Acc: 91.79%, Val Acc: 97.13%\n",
      "Epoch [20/20], Loss: 0.4725, Train Acc: 92.20%, Val Acc: 96.80%\n",
      "\n",
      "Testing with Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.2\n",
      "Epoch [1/20], Loss: 4.1922, Train Acc: 4.35%, Val Acc: 8.19%\n",
      "Epoch [2/20], Loss: 2.8825, Train Acc: 27.49%, Val Acc: 29.37%\n",
      "Epoch [3/20], Loss: 1.4261, Train Acc: 65.77%, Val Acc: 60.44%\n",
      "Epoch [4/20], Loss: 0.6095, Train Acc: 87.79%, Val Acc: 72.53%\n",
      "Epoch [5/20], Loss: 0.2953, Train Acc: 94.39%, Val Acc: 91.81%\n",
      "Epoch [6/20], Loss: 0.1532, Train Acc: 98.14%, Val Acc: 98.90%\n",
      "Epoch [7/20], Loss: 0.1239, Train Acc: 98.52%, Val Acc: 98.70%\n",
      "Epoch [8/20], Loss: 0.1060, Train Acc: 98.85%, Val Acc: 99.40%\n",
      "Epoch [9/20], Loss: 0.0939, Train Acc: 99.24%, Val Acc: 99.20%\n",
      "Epoch [10/20], Loss: 0.0906, Train Acc: 99.06%, Val Acc: 99.60%\n",
      "Epoch [11/20], Loss: 0.0823, Train Acc: 99.20%, Val Acc: 99.50%\n",
      "Epoch [12/20], Loss: 0.0789, Train Acc: 99.26%, Val Acc: 99.40%\n",
      "Epoch [13/20], Loss: 0.0783, Train Acc: 99.37%, Val Acc: 99.50%\n",
      "Epoch [14/20], Loss: 0.0742, Train Acc: 99.46%, Val Acc: 99.30%\n",
      "Epoch [15/20], Loss: 0.0736, Train Acc: 99.42%, Val Acc: 99.80%\n",
      "Epoch [16/20], Loss: 0.0732, Train Acc: 99.39%, Val Acc: 99.70%\n",
      "Epoch [17/20], Loss: 0.0742, Train Acc: 99.27%, Val Acc: 99.30%\n",
      "Epoch [18/20], Loss: 0.0723, Train Acc: 99.55%, Val Acc: 99.30%\n",
      "Epoch [19/20], Loss: 0.0676, Train Acc: 99.55%, Val Acc: 99.80%\n",
      "Epoch [20/20], Loss: 0.0741, Train Acc: 99.29%, Val Acc: 99.30%\n",
      "\n",
      "Testing with Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.3\n",
      "Epoch [1/20], Loss: 4.2617, Train Acc: 3.79%, Val Acc: 3.30%\n",
      "Epoch [2/20], Loss: 2.9170, Train Acc: 25.98%, Val Acc: 16.58%\n",
      "Epoch [3/20], Loss: 1.5372, Train Acc: 61.88%, Val Acc: 37.46%\n",
      "Epoch [4/20], Loss: 0.7084, Train Acc: 84.57%, Val Acc: 88.21%\n",
      "Epoch [5/20], Loss: 0.3635, Train Acc: 92.87%, Val Acc: 86.01%\n",
      "Epoch [6/20], Loss: 0.1992, Train Acc: 97.05%, Val Acc: 97.60%\n",
      "Epoch [7/20], Loss: 0.1722, Train Acc: 97.51%, Val Acc: 99.30%\n",
      "Epoch [8/20], Loss: 0.1483, Train Acc: 98.02%, Val Acc: 99.10%\n",
      "Epoch [9/20], Loss: 0.1347, Train Acc: 98.21%, Val Acc: 99.20%\n",
      "Epoch [10/20], Loss: 0.1222, Train Acc: 98.37%, Val Acc: 99.50%\n",
      "Epoch [11/20], Loss: 0.1107, Train Acc: 98.94%, Val Acc: 99.50%\n",
      "Epoch [12/20], Loss: 0.1092, Train Acc: 98.76%, Val Acc: 99.60%\n",
      "Epoch [13/20], Loss: 0.1022, Train Acc: 99.10%, Val Acc: 99.40%\n",
      "Epoch [14/20], Loss: 0.1048, Train Acc: 98.97%, Val Acc: 99.70%\n",
      "Epoch [15/20], Loss: 0.1055, Train Acc: 98.80%, Val Acc: 99.50%\n",
      "Epoch [16/20], Loss: 0.0994, Train Acc: 99.12%, Val Acc: 99.60%\n",
      "Epoch [17/20], Loss: 0.0996, Train Acc: 98.84%, Val Acc: 99.60%\n",
      "Epoch [18/20], Loss: 0.1005, Train Acc: 98.90%, Val Acc: 99.60%\n",
      "Epoch [19/20], Loss: 0.1024, Train Acc: 98.84%, Val Acc: 99.30%\n",
      "Epoch [20/20], Loss: 0.1033, Train Acc: 98.79%, Val Acc: 99.50%\n",
      "\n",
      "Testing with Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.4\n",
      "Epoch [1/20], Loss: 4.3351, Train Acc: 3.48%, Val Acc: 6.09%\n",
      "Epoch [2/20], Loss: 3.2409, Train Acc: 20.42%, Val Acc: 23.28%\n",
      "Epoch [3/20], Loss: 1.7809, Train Acc: 55.98%, Val Acc: 29.07%\n",
      "Epoch [4/20], Loss: 0.9366, Train Acc: 78.81%, Val Acc: 64.64%\n",
      "Epoch [5/20], Loss: 0.5504, Train Acc: 87.81%, Val Acc: 82.02%\n",
      "Epoch [6/20], Loss: 0.3398, Train Acc: 93.75%, Val Acc: 98.10%\n",
      "Epoch [7/20], Loss: 0.2806, Train Acc: 95.59%, Val Acc: 98.20%\n",
      "Epoch [8/20], Loss: 0.2563, Train Acc: 95.89%, Val Acc: 99.40%\n",
      "Epoch [9/20], Loss: 0.2264, Train Acc: 96.62%, Val Acc: 98.40%\n",
      "Epoch [10/20], Loss: 0.2152, Train Acc: 96.79%, Val Acc: 98.80%\n",
      "Epoch [11/20], Loss: 0.1941, Train Acc: 97.20%, Val Acc: 99.00%\n",
      "Epoch [12/20], Loss: 0.1923, Train Acc: 97.14%, Val Acc: 98.70%\n",
      "Epoch [13/20], Loss: 0.1840, Train Acc: 97.47%, Val Acc: 98.90%\n",
      "Epoch [14/20], Loss: 0.1819, Train Acc: 97.47%, Val Acc: 99.40%\n",
      "Epoch [15/20], Loss: 0.1833, Train Acc: 97.32%, Val Acc: 99.20%\n",
      "Epoch [16/20], Loss: 0.1748, Train Acc: 97.77%, Val Acc: 99.10%\n",
      "Epoch [17/20], Loss: 0.1805, Train Acc: 97.49%, Val Acc: 98.90%\n",
      "Epoch [18/20], Loss: 0.1799, Train Acc: 97.42%, Val Acc: 99.00%\n",
      "Epoch [19/20], Loss: 0.1781, Train Acc: 97.42%, Val Acc: 99.30%\n",
      "Epoch [20/20], Loss: 0.1756, Train Acc: 97.60%, Val Acc: 99.20%\n",
      "\n",
      "Testing with Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.5\n",
      "Epoch [1/20], Loss: 4.3824, Train Acc: 3.14%, Val Acc: 7.39%\n",
      "Epoch [2/20], Loss: 3.5613, Train Acc: 12.38%, Val Acc: 18.58%\n",
      "Epoch [3/20], Loss: 2.3044, Train Acc: 39.00%, Val Acc: 60.64%\n",
      "Epoch [4/20], Loss: 1.4666, Train Acc: 62.43%, Val Acc: 50.05%\n",
      "Epoch [5/20], Loss: 0.9328, Train Acc: 76.13%, Val Acc: 87.01%\n",
      "Epoch [6/20], Loss: 0.6401, Train Acc: 85.80%, Val Acc: 95.30%\n",
      "Epoch [7/20], Loss: 0.5553, Train Acc: 88.85%, Val Acc: 95.70%\n",
      "Epoch [8/20], Loss: 0.4965, Train Acc: 90.00%, Val Acc: 97.30%\n",
      "Epoch [9/20], Loss: 0.4644, Train Acc: 90.69%, Val Acc: 98.00%\n",
      "Epoch [10/20], Loss: 0.4391, Train Acc: 91.22%, Val Acc: 98.10%\n",
      "Epoch [11/20], Loss: 0.4057, Train Acc: 92.10%, Val Acc: 97.80%\n",
      "Epoch [12/20], Loss: 0.4052, Train Acc: 92.49%, Val Acc: 98.50%\n",
      "Epoch [13/20], Loss: 0.3892, Train Acc: 92.95%, Val Acc: 98.20%\n",
      "Epoch [14/20], Loss: 0.3899, Train Acc: 92.90%, Val Acc: 98.30%\n",
      "Epoch [15/20], Loss: 0.3907, Train Acc: 92.51%, Val Acc: 97.70%\n",
      "Epoch [16/20], Loss: 0.3816, Train Acc: 92.87%, Val Acc: 97.40%\n",
      "Epoch [17/20], Loss: 0.3910, Train Acc: 92.46%, Val Acc: 98.40%\n",
      "Epoch [18/20], Loss: 0.3884, Train Acc: 92.76%, Val Acc: 98.00%\n",
      "Epoch [19/20], Loss: 0.3856, Train Acc: 92.60%, Val Acc: 97.50%\n",
      "Epoch [20/20], Loss: 0.3773, Train Acc: 92.92%, Val Acc: 98.20%\n",
      "\n",
      "Test Results:\n",
      "Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.2 | Best Val Acc: 99.25%, Test Acc: 99.00%\n",
      "Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.3 | Best Val Acc: 99.55%, Test Acc: 98.80%\n",
      "Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.4 | Best Val Acc: 99.10%, Test Acc: 97.90%\n",
      "Training: 70.0%, Validation: 20.0%, Testing: 10.0%, Dropout: 0.5 | Best Val Acc: 90.65%, Test Acc: 90.70%\n",
      "Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.2 | Best Val Acc: 99.47%, Test Acc: 98.47%\n",
      "Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.3 | Best Val Acc: 99.40%, Test Acc: 98.87%\n",
      "Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.4 | Best Val Acc: 97.13%, Test Acc: 95.20%\n",
      "Training: 75.0%, Validation: 15.0%, Testing: 15.0%, Dropout: 0.5 | Best Val Acc: 97.47%, Test Acc: 96.53%\n",
      "Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.2 | Best Val Acc: 99.80%, Test Acc: 99.70%\n",
      "Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.3 | Best Val Acc: 99.70%, Test Acc: 99.00%\n",
      "Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.4 | Best Val Acc: 99.40%, Test Acc: 98.30%\n",
      "Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.5 | Best Val Acc: 98.50%, Test Acc: 97.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "def test_loop():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Data transforms with augmentation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    dataset = WordImageDataset('content/dataset/easy', transform=transform)\n",
    "\n",
    "    train_ratios = [0.7, 0.75, 0.8]\n",
    "    val_test_ratios = [\n",
    "        (0.2, 0.1),  \n",
    "        (0.15, 0.15),  \n",
    "        (0.1, 0.1) \n",
    "    ]\n",
    "\n",
    "    dropout_rates = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "    results = {}\n",
    "    for train_ratio, (val_ratio, test_ratio) in zip(train_ratios, val_test_ratios):\n",
    "        for dropout_rate in dropout_rates:\n",
    "            print(f\"\\nTesting with Training: {train_ratio*100}%, Validation: {val_ratio*100}%, \"\n",
    "                  f\"Testing: {test_ratio*100}%, Dropout: {dropout_rate}\")\n",
    "\n",
    "            train_indices, test_indices = train_test_split(\n",
    "                range(len(dataset)), test_size=test_ratio, random_state=42)\n",
    "            train_indices, val_indices = train_test_split(\n",
    "                train_indices, test_size=val_ratio / (1 - test_ratio), random_state=42)\n",
    "\n",
    "            train_dataset = Subset(dataset, train_indices)\n",
    "            val_dataset = Subset(dataset, val_indices)\n",
    "            test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "            model = WordCNN(num_classes=len(dataset.label_to_idx), dropout_rate=dropout_rate).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "            scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "            best_val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "\n",
    "            model.load_state_dict(torch.load('best_model.pth'))\n",
    "            model.eval()\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_acc = 100 * test_correct / test_total\n",
    "            results[(train_ratio, val_ratio, test_ratio, dropout_rate)] = (best_val_acc, test_acc)\n",
    "\n",
    "    print(\"\\nTest Results:\")\n",
    "    for (train_ratio, val_ratio, test_ratio, dropout_rate), (val_acc, test_acc) in results.items():\n",
    "        print(f\"Training: {train_ratio*100}%, Validation: {val_ratio*100}%, Testing: {test_ratio*100}%, \"\n",
    "              f\"Dropout: {dropout_rate} | Best Val Acc: {val_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training: 80.0%, Validation: 10.0%, Testing: 10.0%, Dropout: 0.2 | Best Val Acc: 99.80%, Test Acc: 99.70%`\n",
    "- This was the best configuration observed for the easy set and henceforth the following hyperparameters were fixed for further sets.\n",
    "    - Training-Validation-Test Split = 80 : 10 : 10\n",
    "    - Dropout - 0.2\n",
    "    - Activation function - nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Dataset Size\n",
    "- Obviously when we feed a larger dataset to a model, the accuracy increases. But the time and computation may not be a valid tradeoff,\n",
    "- To see this, a loop with datasets containing 25, 50, 75, 100, 125, 150, 175 and 200 images per label (word) have been generated and their accuracy has been plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated: content/dataset/easy_25 with 25 images per label\n",
      "Dataset generated: content/dataset/easy_50 with 50 images per label\n",
      "Dataset generated: content/dataset/easy_75 with 75 images per label\n",
      "Dataset generated: content/dataset/easy_100 with 100 images per label\n",
      "Dataset generated: content/dataset/easy_125 with 125 images per label\n",
      "Dataset generated: content/dataset/easy_150 with 150 images per label\n",
      "Dataset generated: content/dataset/easy_175 with 175 images per label\n",
      "Dataset generated: content/dataset/easy_200 with 200 images per label\n"
     ]
    }
   ],
   "source": [
    "def generate_datasets(words, font_path, base_output_dir=\"content/dataset/easy\", sizes=[25, 50, 75, 100, 125, 150, 175, 200]):\n",
    "    if not os.path.exists(font_path):\n",
    "        raise FileNotFoundError(f\"Font file not found: {font_path}\")\n",
    "    \n",
    "    for size in sizes:\n",
    "        output_dir = f\"{base_output_dir}_{size}\"\n",
    "        if os.path.exists(output_dir):\n",
    "            shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        for i in range(size):\n",
    "            for word in words:\n",
    "                width, height = 248, 80\n",
    "                image = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                try:\n",
    "                    font = ImageFont.truetype(font_path, 36)\n",
    "                except OSError as e:\n",
    "                    print(f\"Error loading font: {e}\")\n",
    "                    return\n",
    "                text = word.title()\n",
    "                text_bbox = font.getbbox(word)\n",
    "                text_width = text_bbox[2] - text_bbox[0]\n",
    "                text_height = text_bbox[3] - text_bbox[1]\n",
    "                # Random positioning\n",
    "                x = random.randint((width - text_width)//8, 7*((width - text_width)//8))\n",
    "                y = random.randint((height - text_height)//8, 7*((height - text_height)//8))\n",
    "                position = (x, y)\n",
    "                draw.text(position, text, font=font, fill=(0, 0, 0))\n",
    "                image.save(os.path.join(output_dir, f\"{word}_{i}.png\"))\n",
    "        \n",
    "        print(f\"Dataset generated: {output_dir} with {size} images per label\")\n",
    "\n",
    "generate_datasets(words=words, font_path = \"Fonts/OpenSans-Regular.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 4.6594, Train Acc: 1.85%, Val Acc: 0.80%\n",
      "Epoch [2/20], Loss: 4.1956, Train Acc: 4.60%, Val Acc: 3.19%\n",
      "Epoch [3/20], Loss: 3.9150, Train Acc: 6.65%, Val Acc: 3.19%\n",
      "Epoch [4/20], Loss: 3.5864, Train Acc: 12.41%, Val Acc: 1.99%\n",
      "Epoch [5/20], Loss: 3.1457, Train Acc: 22.76%, Val Acc: 7.57%\n",
      "Epoch [6/20], Loss: 2.5346, Train Acc: 42.92%, Val Acc: 30.28%\n",
      "Epoch [7/20], Loss: 2.3656, Train Acc: 48.32%, Val Acc: 28.69%\n",
      "Epoch [8/20], Loss: 2.2559, Train Acc: 53.03%, Val Acc: 34.26%\n",
      "Epoch [9/20], Loss: 2.1255, Train Acc: 58.23%, Val Acc: 38.25%\n",
      "Epoch [10/20], Loss: 2.0386, Train Acc: 59.03%, Val Acc: 37.45%\n",
      "Epoch [11/20], Loss: 1.9254, Train Acc: 65.48%, Val Acc: 39.84%\n",
      "Epoch [12/20], Loss: 1.9099, Train Acc: 64.88%, Val Acc: 41.83%\n",
      "Epoch [13/20], Loss: 1.9076, Train Acc: 65.48%, Val Acc: 38.65%\n",
      "Epoch [14/20], Loss: 1.8772, Train Acc: 65.18%, Val Acc: 42.23%\n",
      "Epoch [15/20], Loss: 1.8740, Train Acc: 67.08%, Val Acc: 41.04%\n",
      "Epoch [16/20], Loss: 1.8738, Train Acc: 66.93%, Val Acc: 39.44%\n",
      "Epoch [17/20], Loss: 1.8865, Train Acc: 65.78%, Val Acc: 40.64%\n",
      "Epoch [18/20], Loss: 1.8744, Train Acc: 66.68%, Val Acc: 41.43%\n",
      "Epoch [19/20], Loss: 1.8690, Train Acc: 66.68%, Val Acc: 41.43%\n",
      "Epoch [20/20], Loss: 1.8646, Train Acc: 66.83%, Val Acc: 39.44%\n",
      "Dataset 25 images/label | Val Acc: 42.23%, Test Acc: 41.20%\n",
      "Epoch [1/20], Loss: 4.4827, Train Acc: 2.73%, Val Acc: 3.39%\n",
      "Epoch [2/20], Loss: 3.9327, Train Acc: 5.90%, Val Acc: 7.98%\n",
      "Epoch [3/20], Loss: 3.4698, Train Acc: 13.55%, Val Acc: 19.36%\n",
      "Epoch [4/20], Loss: 2.6755, Train Acc: 32.33%, Val Acc: 26.95%\n",
      "Epoch [5/20], Loss: 1.9486, Train Acc: 51.71%, Val Acc: 25.35%\n",
      "Epoch [6/20], Loss: 1.4416, Train Acc: 68.19%, Val Acc: 72.85%\n",
      "Epoch [7/20], Loss: 1.3228, Train Acc: 73.97%, Val Acc: 75.65%\n",
      "Epoch [8/20], Loss: 1.2416, Train Acc: 76.29%, Val Acc: 77.45%\n",
      "Epoch [9/20], Loss: 1.1729, Train Acc: 78.67%, Val Acc: 80.04%\n",
      "Epoch [10/20], Loss: 1.0959, Train Acc: 81.02%, Val Acc: 80.44%\n",
      "Epoch [11/20], Loss: 1.0411, Train Acc: 82.57%, Val Acc: 81.84%\n",
      "Epoch [12/20], Loss: 1.0348, Train Acc: 83.25%, Val Acc: 81.64%\n",
      "Epoch [13/20], Loss: 1.0181, Train Acc: 83.60%, Val Acc: 83.83%\n",
      "Epoch [14/20], Loss: 1.0042, Train Acc: 84.20%, Val Acc: 82.04%\n",
      "Epoch [15/20], Loss: 1.0043, Train Acc: 84.12%, Val Acc: 82.44%\n",
      "Epoch [16/20], Loss: 1.0074, Train Acc: 84.10%, Val Acc: 83.83%\n",
      "Epoch [17/20], Loss: 1.0208, Train Acc: 83.80%, Val Acc: 83.63%\n",
      "Epoch [18/20], Loss: 0.9985, Train Acc: 84.35%, Val Acc: 83.83%\n",
      "Epoch [19/20], Loss: 1.0113, Train Acc: 83.82%, Val Acc: 84.83%\n",
      "Epoch [20/20], Loss: 1.0146, Train Acc: 82.77%, Val Acc: 82.63%\n",
      "Dataset 50 images/label | Val Acc: 84.83%, Test Acc: 81.80%\n",
      "Epoch [1/20], Loss: 4.4803, Train Acc: 2.30%, Val Acc: 2.93%\n",
      "Epoch [2/20], Loss: 3.8152, Train Acc: 7.33%, Val Acc: 12.93%\n",
      "Epoch [3/20], Loss: 2.7145, Train Acc: 31.45%, Val Acc: 45.47%\n",
      "Epoch [4/20], Loss: 1.5074, Train Acc: 64.42%, Val Acc: 64.93%\n",
      "Epoch [5/20], Loss: 0.8226, Train Acc: 82.68%, Val Acc: 87.20%\n",
      "Epoch [6/20], Loss: 0.4546, Train Acc: 92.72%, Val Acc: 94.80%\n",
      "Epoch [7/20], Loss: 0.3754, Train Acc: 95.47%, Val Acc: 95.07%\n",
      "Epoch [8/20], Loss: 0.3312, Train Acc: 95.85%, Val Acc: 96.93%\n",
      "Epoch [9/20], Loss: 0.2918, Train Acc: 96.75%, Val Acc: 97.73%\n",
      "Epoch [10/20], Loss: 0.2656, Train Acc: 97.12%, Val Acc: 97.87%\n",
      "Epoch [11/20], Loss: 0.2423, Train Acc: 97.37%, Val Acc: 97.87%\n",
      "Epoch [12/20], Loss: 0.2379, Train Acc: 97.68%, Val Acc: 97.60%\n",
      "Epoch [13/20], Loss: 0.2363, Train Acc: 97.72%, Val Acc: 98.00%\n",
      "Epoch [14/20], Loss: 0.2301, Train Acc: 97.68%, Val Acc: 97.33%\n",
      "Epoch [15/20], Loss: 0.2243, Train Acc: 97.95%, Val Acc: 98.27%\n",
      "Epoch [16/20], Loss: 0.2258, Train Acc: 97.60%, Val Acc: 98.00%\n",
      "Epoch [17/20], Loss: 0.2318, Train Acc: 97.80%, Val Acc: 97.47%\n",
      "Epoch [18/20], Loss: 0.2274, Train Acc: 97.53%, Val Acc: 98.00%\n",
      "Epoch [19/20], Loss: 0.2196, Train Acc: 97.97%, Val Acc: 98.93%\n",
      "Epoch [20/20], Loss: 0.2226, Train Acc: 98.12%, Val Acc: 97.73%\n",
      "Dataset 75 images/label | Val Acc: 98.93%, Test Acc: 98.40%\n",
      "Epoch [1/20], Loss: 4.2071, Train Acc: 4.65%, Val Acc: 6.99%\n",
      "Epoch [2/20], Loss: 2.7061, Train Acc: 31.73%, Val Acc: 13.99%\n",
      "Epoch [3/20], Loss: 1.3853, Train Acc: 65.81%, Val Acc: 35.96%\n",
      "Epoch [4/20], Loss: 0.6524, Train Acc: 86.67%, Val Acc: 61.74%\n",
      "Epoch [5/20], Loss: 0.3124, Train Acc: 94.47%, Val Acc: 62.04%\n",
      "Epoch [6/20], Loss: 0.1653, Train Acc: 97.70%, Val Acc: 98.40%\n",
      "Epoch [7/20], Loss: 0.1278, Train Acc: 98.36%, Val Acc: 99.20%\n",
      "Epoch [8/20], Loss: 0.1068, Train Acc: 98.94%, Val Acc: 99.10%\n",
      "Epoch [9/20], Loss: 0.0978, Train Acc: 98.91%, Val Acc: 99.20%\n",
      "Epoch [10/20], Loss: 0.0854, Train Acc: 99.30%, Val Acc: 99.40%\n",
      "Epoch [11/20], Loss: 0.0819, Train Acc: 99.19%, Val Acc: 99.80%\n",
      "Epoch [12/20], Loss: 0.0806, Train Acc: 99.06%, Val Acc: 99.30%\n",
      "Epoch [13/20], Loss: 0.0767, Train Acc: 99.35%, Val Acc: 99.60%\n",
      "Epoch [14/20], Loss: 0.0743, Train Acc: 99.31%, Val Acc: 99.80%\n",
      "Epoch [15/20], Loss: 0.0735, Train Acc: 99.25%, Val Acc: 99.60%\n",
      "Epoch [16/20], Loss: 0.0752, Train Acc: 99.27%, Val Acc: 99.70%\n",
      "Epoch [17/20], Loss: 0.0736, Train Acc: 99.22%, Val Acc: 99.40%\n",
      "Epoch [18/20], Loss: 0.0725, Train Acc: 99.19%, Val Acc: 99.10%\n",
      "Epoch [19/20], Loss: 0.0720, Train Acc: 99.37%, Val Acc: 99.80%\n",
      "Epoch [20/20], Loss: 0.0738, Train Acc: 99.21%, Val Acc: 98.80%\n",
      "Dataset 100 images/label | Val Acc: 99.80%, Test Acc: 99.40%\n",
      "Epoch [1/20], Loss: 4.1572, Train Acc: 4.61%, Val Acc: 1.28%\n",
      "Epoch [2/20], Loss: 2.6808, Train Acc: 31.89%, Val Acc: 23.52%\n",
      "Epoch [3/20], Loss: 1.0760, Train Acc: 75.52%, Val Acc: 83.92%\n",
      "Epoch [4/20], Loss: 0.4590, Train Acc: 90.99%, Val Acc: 94.56%\n",
      "Epoch [5/20], Loss: 0.2091, Train Acc: 96.17%, Val Acc: 96.56%\n",
      "Epoch [6/20], Loss: 0.1066, Train Acc: 98.48%, Val Acc: 99.28%\n",
      "Epoch [7/20], Loss: 0.0849, Train Acc: 98.75%, Val Acc: 99.52%\n",
      "Epoch [8/20], Loss: 0.0766, Train Acc: 99.13%, Val Acc: 99.76%\n",
      "Epoch [9/20], Loss: 0.0618, Train Acc: 99.39%, Val Acc: 99.44%\n",
      "Epoch [10/20], Loss: 0.0557, Train Acc: 99.41%, Val Acc: 99.84%\n",
      "Epoch [11/20], Loss: 0.0520, Train Acc: 99.47%, Val Acc: 99.52%\n",
      "Epoch [12/20], Loss: 0.0514, Train Acc: 99.47%, Val Acc: 99.68%\n",
      "Epoch [13/20], Loss: 0.0491, Train Acc: 99.47%, Val Acc: 99.60%\n",
      "Epoch [14/20], Loss: 0.0459, Train Acc: 99.59%, Val Acc: 99.76%\n",
      "Epoch [15/20], Loss: 0.0472, Train Acc: 99.62%, Val Acc: 99.92%\n",
      "Epoch [16/20], Loss: 0.0479, Train Acc: 99.52%, Val Acc: 99.84%\n",
      "Epoch [17/20], Loss: 0.0482, Train Acc: 99.51%, Val Acc: 99.84%\n",
      "Epoch [18/20], Loss: 0.0452, Train Acc: 99.61%, Val Acc: 99.68%\n",
      "Epoch [19/20], Loss: 0.0463, Train Acc: 99.55%, Val Acc: 99.60%\n",
      "Epoch [20/20], Loss: 0.0453, Train Acc: 99.56%, Val Acc: 99.84%\n",
      "Dataset 125 images/label | Val Acc: 99.92%, Test Acc: 99.60%\n",
      "Epoch [1/20], Loss: 3.8614, Train Acc: 10.21%, Val Acc: 7.60%\n",
      "Epoch [2/20], Loss: 1.5551, Train Acc: 62.21%, Val Acc: 45.20%\n",
      "Epoch [3/20], Loss: 0.5054, Train Acc: 90.05%, Val Acc: 96.13%\n",
      "Epoch [4/20], Loss: 0.1924, Train Acc: 96.59%, Val Acc: 95.07%\n",
      "Epoch [5/20], Loss: 0.1048, Train Acc: 98.12%, Val Acc: 68.53%\n",
      "Epoch [6/20], Loss: 0.0477, Train Acc: 99.38%, Val Acc: 99.87%\n",
      "Epoch [7/20], Loss: 0.0381, Train Acc: 99.48%, Val Acc: 99.47%\n",
      "Epoch [8/20], Loss: 0.0313, Train Acc: 99.58%, Val Acc: 99.80%\n",
      "Epoch [9/20], Loss: 0.0285, Train Acc: 99.66%, Val Acc: 99.93%\n",
      "Epoch [10/20], Loss: 0.0250, Train Acc: 99.72%, Val Acc: 99.60%\n",
      "Epoch [11/20], Loss: 0.0248, Train Acc: 99.72%, Val Acc: 100.00%\n",
      "Epoch [12/20], Loss: 0.0210, Train Acc: 99.83%, Val Acc: 99.87%\n",
      "Epoch [13/20], Loss: 0.0212, Train Acc: 99.78%, Val Acc: 99.87%\n",
      "Epoch [14/20], Loss: 0.0202, Train Acc: 99.85%, Val Acc: 99.93%\n",
      "Epoch [15/20], Loss: 0.0207, Train Acc: 99.80%, Val Acc: 100.00%\n",
      "Epoch [16/20], Loss: 0.0192, Train Acc: 99.78%, Val Acc: 99.93%\n",
      "Epoch [17/20], Loss: 0.0207, Train Acc: 99.81%, Val Acc: 99.80%\n",
      "Epoch [18/20], Loss: 0.0218, Train Acc: 99.75%, Val Acc: 99.93%\n",
      "Epoch [19/20], Loss: 0.0194, Train Acc: 99.82%, Val Acc: 99.73%\n",
      "Epoch [20/20], Loss: 0.0213, Train Acc: 99.72%, Val Acc: 100.00%\n",
      "Dataset 150 images/label | Val Acc: 100.00%, Test Acc: 99.93%\n",
      "Epoch [1/20], Loss: 3.7049, Train Acc: 12.42%, Val Acc: 35.58%\n",
      "Epoch [2/20], Loss: 1.3993, Train Acc: 66.01%, Val Acc: 38.78%\n",
      "Epoch [3/20], Loss: 0.4233, Train Acc: 91.59%, Val Acc: 97.03%\n",
      "Epoch [4/20], Loss: 0.1656, Train Acc: 96.81%, Val Acc: 89.55%\n",
      "Epoch [5/20], Loss: 0.0847, Train Acc: 98.49%, Val Acc: 97.94%\n",
      "Epoch [6/20], Loss: 0.0385, Train Acc: 99.47%, Val Acc: 99.77%\n",
      "Epoch [7/20], Loss: 0.0283, Train Acc: 99.71%, Val Acc: 99.83%\n",
      "Epoch [8/20], Loss: 0.0255, Train Acc: 99.69%, Val Acc: 99.94%\n",
      "Epoch [9/20], Loss: 0.0221, Train Acc: 99.76%, Val Acc: 99.89%\n",
      "Epoch [10/20], Loss: 0.0210, Train Acc: 99.75%, Val Acc: 99.94%\n",
      "Epoch [11/20], Loss: 0.0176, Train Acc: 99.81%, Val Acc: 99.89%\n",
      "Epoch [12/20], Loss: 0.0169, Train Acc: 99.84%, Val Acc: 99.89%\n",
      "Epoch [13/20], Loss: 0.0167, Train Acc: 99.84%, Val Acc: 99.94%\n",
      "Epoch [14/20], Loss: 0.0158, Train Acc: 99.81%, Val Acc: 99.94%\n",
      "Epoch [15/20], Loss: 0.0142, Train Acc: 99.89%, Val Acc: 99.66%\n",
      "Epoch [16/20], Loss: 0.0144, Train Acc: 99.88%, Val Acc: 99.94%\n",
      "Epoch [17/20], Loss: 0.0150, Train Acc: 99.85%, Val Acc: 99.94%\n",
      "Epoch [18/20], Loss: 0.0141, Train Acc: 99.89%, Val Acc: 99.89%\n",
      "Epoch [19/20], Loss: 0.0149, Train Acc: 99.86%, Val Acc: 99.89%\n",
      "Epoch [20/20], Loss: 0.0151, Train Acc: 99.86%, Val Acc: 99.89%\n",
      "Dataset 175 images/label | Val Acc: 99.94%, Test Acc: 99.89%\n",
      "Epoch [1/20], Loss: 3.6038, Train Acc: 15.51%, Val Acc: 36.63%\n",
      "Epoch [2/20], Loss: 0.9570, Train Acc: 78.35%, Val Acc: 59.77%\n",
      "Epoch [3/20], Loss: 0.2351, Train Acc: 95.65%, Val Acc: 46.48%\n",
      "Epoch [4/20], Loss: 0.1038, Train Acc: 98.02%, Val Acc: 92.30%\n",
      "Epoch [5/20], Loss: 0.0654, Train Acc: 98.67%, Val Acc: 70.21%\n",
      "Epoch [6/20], Loss: 0.0303, Train Acc: 99.50%, Val Acc: 99.80%\n",
      "Epoch [7/20], Loss: 0.0198, Train Acc: 99.73%, Val Acc: 99.85%\n",
      "Epoch [8/20], Loss: 0.0163, Train Acc: 99.81%, Val Acc: 99.90%\n",
      "Epoch [9/20], Loss: 0.0147, Train Acc: 99.77%, Val Acc: 99.90%\n",
      "Epoch [10/20], Loss: 0.0129, Train Acc: 99.82%, Val Acc: 99.95%\n",
      "Epoch [11/20], Loss: 0.0107, Train Acc: 99.89%, Val Acc: 100.00%\n",
      "Epoch [12/20], Loss: 0.0109, Train Acc: 99.88%, Val Acc: 99.90%\n",
      "Epoch [13/20], Loss: 0.0102, Train Acc: 99.89%, Val Acc: 100.00%\n",
      "Epoch [14/20], Loss: 0.0103, Train Acc: 99.88%, Val Acc: 100.00%\n",
      "Epoch [15/20], Loss: 0.0104, Train Acc: 99.87%, Val Acc: 99.95%\n",
      "Epoch [16/20], Loss: 0.0098, Train Acc: 99.87%, Val Acc: 100.00%\n",
      "Epoch [17/20], Loss: 0.0105, Train Acc: 99.86%, Val Acc: 99.95%\n",
      "Epoch [18/20], Loss: 0.0107, Train Acc: 99.89%, Val Acc: 99.95%\n",
      "Epoch [19/20], Loss: 0.0095, Train Acc: 99.88%, Val Acc: 100.00%\n",
      "Epoch [20/20], Loss: 0.0097, Train Acc: 99.89%, Val Acc: 99.95%\n",
      "Dataset 200 images/label | Val Acc: 100.00%, Test Acc: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        self.idx_to_label = {}\n",
    "\n",
    "        # Get all unique words (labels)\n",
    "        words = set()\n",
    "        for filename in os.listdir(image_dir):\n",
    "            word = filename.split('_')[0]\n",
    "            words.add(word)\n",
    "\n",
    "        # Create label mappings\n",
    "        for idx, word in enumerate(sorted(words)):\n",
    "            self.label_to_idx[word] = idx\n",
    "            self.idx_to_label[idx] = word\n",
    "\n",
    "        # Load all images and labels\n",
    "        for filename in os.listdir(image_dir):\n",
    "            if filename.endswith('.png'):\n",
    "                word = filename.split('_')[0]\n",
    "                self.images.append(os.path.join(image_dir, filename))\n",
    "                self.labels.append(self.label_to_idx[word])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def test_loop():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dropout_rate = 0.2\n",
    "    train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "    dataset_sizes = [25, 50, 75, 100, 125, 150, 175, 200]\n",
    "    results = {}\n",
    "    \n",
    "    for size in dataset_sizes:\n",
    "        dataset_path = f'content/dataset/easy_{size}'\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((248, 80)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "        dataset = WordImageDataset(dataset_path, transform=transform)\n",
    "        train_indices, test_indices = train_test_split(range(len(dataset)), test_size=test_ratio, random_state=42)\n",
    "        train_indices, val_indices = train_test_split(train_indices, test_size=val_ratio / (1 - test_ratio), random_state=42)\n",
    "        \n",
    "        train_dataset = Subset(dataset, train_indices)\n",
    "        val_dataset = Subset(dataset, val_indices)\n",
    "        test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        model = WordCNN(num_classes=len(dataset.label_to_idx), dropout_rate=dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "        \n",
    "        best_val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "        \n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "        model.eval()\n",
    "        test_correct, test_total = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        results[size] = (best_val_acc, test_acc)\n",
    "        print(f\"Dataset {size} images/label | Val Acc: {best_val_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Plot results\n",
    "    sizes = list(results.keys())\n",
    "    val_accs = [results[size][0] for size in sizes]\n",
    "    test_accs = [results[size][1] for size in sizes]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sizes, val_accs, marker='o', label='Validation Accuracy')\n",
    "    plt.plot(sizes, test_accs, marker='s', label='Test Accuracy')\n",
    "    plt.xlabel('Images per Label')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Model Performance vs Dataset Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the results, it is fair to say that 100-125 images per label is the sweet spot where we get resonable accuracy at a lower computation and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the hard set\n",
    "The basic features of this dataset include\n",
    "- Multiple text fonts\n",
    "- The text color is not fixed but background is fixed to be white.\n",
    "- The text is centered.\n",
    "- The text has random capitalisation.\n",
    "- Noise is added in the form of random dots of random colors in varying positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(draw, width, height):\n",
    "    for _ in range(random.randint(4000, 5000)):\n",
    "        x, y = random.randint(0, width - 1), random.randint(0, height - 1)\n",
    "        color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "        draw.point((x, y), fill=color)\n",
    "\n",
    "FONTS = [\n",
    "    \"Fonts/akira.ttf\",\n",
    "    \"Fonts/dejavu-sans-bold.ttf\",\n",
    "    \"Fonts/Roboto-Italic.ttf\",\n",
    "    \"Fonts/Roboto.ttf\",\n",
    "    \"Fonts/Harabara.ttf\",\n",
    "    \"Fonts/Designer.ttf\",\n",
    "    \"Fonts/OpenSans-Italic.ttf\",\n",
    "    \"Fonts/OpenSans-Regular.ttf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"content/dataset/hard\"):\n",
    "    shutil.rmtree(\"content/dataset/hard\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/hard\"):\n",
    "    os.makedirs(\"content/dataset/hard\")\n",
    "\n",
    "def generate_hard_set():\n",
    "    for i in range(0,200):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            # generate image with white only\n",
    "            img = Image.new(\"RGB\", (width, height), color=\"white\")\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # generate fonts with random fonts and colors\n",
    "            font = ImageFont.truetype(random.choice(FONTS), size = 30)\n",
    "            text_color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "            \n",
    "            # generate fonts with random capitalization\n",
    "            word_variation = ''.join(random.choice([c.upper(), c.lower()]) for c in word)\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            position = ((width - text_width) // 2, (height - text_height) // 2)\n",
    "\n",
    "            draw.text(position, word_variation, fill=text_color, font=font)\n",
    "\n",
    "            # Add noise\n",
    "            add_noise(draw, width, height)\n",
    "\n",
    "            img.save(os.path.join(\"content/dataset/hard\", f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_hard_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes made to model to account for the hard set\n",
    "- Changed the first convolutional layer:\n",
    "    - `nn.Conv2d(1, 32,  kernel_size=3, padding=1)` -> `nn.Conv2d(3, 32,  kernel_size=3, padding=1)`\n",
    "    - This allows the model to handle RGB images instead of grayscale.\n",
    "- Updated dataset processing:\n",
    "    - `Image.open(img_name).convert('L')` -> `Image.open(img_name).convert('RGB')`\n",
    "    - This ensures images are loaded in color.\n",
    "- Adjusted normalization:\n",
    "    - From `mean=[0.5], std=[0.5]` (grayscale) to `mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.4642, Train Acc: 18.02%, Val Acc: 44.05%\n",
      "Epoch [2/20], Loss: 1.4816, Train Acc: 61.86%, Val Acc: 67.90%\n",
      "Epoch [3/20], Loss: 0.8954, Train Acc: 76.43%, Val Acc: 76.25%\n",
      "Epoch [4/20], Loss: 0.6518, Train Acc: 82.19%, Val Acc: 83.90%\n",
      "Epoch [5/20], Loss: 0.5151, Train Acc: 85.34%, Val Acc: 85.35%\n",
      "Epoch [6/20], Loss: 0.3357, Train Acc: 90.89%, Val Acc: 91.10%\n",
      "Epoch [7/20], Loss: 0.2782, Train Acc: 92.83%, Val Acc: 92.60%\n",
      "Epoch [8/20], Loss: 0.2573, Train Acc: 93.55%, Val Acc: 92.25%\n",
      "Epoch [9/20], Loss: 0.2346, Train Acc: 93.91%, Val Acc: 93.20%\n",
      "Epoch [10/20], Loss: 0.2180, Train Acc: 94.35%, Val Acc: 93.10%\n",
      "Epoch [11/20], Loss: 0.2015, Train Acc: 94.89%, Val Acc: 93.20%\n",
      "Epoch [12/20], Loss: 0.1934, Train Acc: 95.27%, Val Acc: 93.35%\n",
      "Epoch [13/20], Loss: 0.1939, Train Acc: 95.23%, Val Acc: 93.15%\n",
      "Epoch [14/20], Loss: 0.1961, Train Acc: 94.99%, Val Acc: 94.05%\n",
      "Epoch [15/20], Loss: 0.1955, Train Acc: 95.04%, Val Acc: 93.50%\n",
      "Epoch [16/20], Loss: 0.1885, Train Acc: 95.08%, Val Acc: 93.55%\n",
      "Epoch [17/20], Loss: 0.1920, Train Acc: 95.12%, Val Acc: 93.95%\n",
      "Epoch [18/20], Loss: 0.1852, Train Acc: 95.36%, Val Acc: 93.70%\n",
      "Epoch [19/20], Loss: 0.1912, Train Acc: 95.24%, Val Acc: 93.10%\n",
      "Epoch [20/20], Loss: 0.1916, Train Acc: 95.12%, Val Acc: 94.00%\n",
      "\n",
      "Final Results:\n",
      "Best Validation Accuracy: 94.05%\n",
      "Test Accuracy: 93.70%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.label_to_idx = {word: idx for idx, word in enumerate(set(f.split('_')[0] for f in self.image_files))}\n",
    "        self.idx_to_label = {idx: word for word, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.image_files[idx].split('_')[0]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return best_val_acc, test_acc\n",
    "\n",
    "def test_loop():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    dataset = WordImageDataset('content/dataset/hard', transform=transform)\n",
    "    train_indices, temp_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=nn.ReLU(), dropout_rate=0.2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    best_val_acc, test_acc = train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple increase from 100 images to 200 images per label showed significant increase in accuracy. The hard set thus benefits greatly from the amount of images to allow the model to overcome underfitting. The high compute time in training however hindered me in doing further tests on larger datasets.\n",
    "- Model accuracy 100 images per label 77.0%\n",
    "- Model accuracy 200 images per label 93.70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now look at what happens if we just convert the hardset to compute grayscale images. Colors may play a huge effect in the training of the model and we need to check only the effects of noise and font differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gray_noise(draw, width, height):\n",
    "    for _ in range(random.randint(4000, 5000)):\n",
    "        x, y = random.randint(0, width - 1), random.randint(0, height - 1)\n",
    "        gray_value = random.randint(0, 255)  # Single grayscale intensity\n",
    "        draw.point((x, y), fill=gray_value)\n",
    "\n",
    "if os.path.exists(\"content/dataset/grayhard\"):\n",
    "    shutil.rmtree(\"content/dataset/grayhard\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/grayhard\"):\n",
    "    os.makedirs(\"content/dataset/grayhard\")\n",
    "\n",
    "def generate_grayhard_set():\n",
    "    for i in range(0,200):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            img = Image.new(\"L\", (width, height), color=255)  # \"L\" mode for grayscale\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # Generate fonts with random selection\n",
    "            font = ImageFont.truetype(random.choice(FONTS), size=30)\n",
    "            \n",
    "            # Grayscale text color (single intensity for R, G, and B)\n",
    "            gray_text_color = random.randint(0, 255)\n",
    "            \n",
    "            # Generate random capitalization\n",
    "            word_variation = ''.join(random.choice([c.upper(), c.lower()]) for c in word)\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            position = ((width - text_width) // 2, (height - text_height) // 2)\n",
    "\n",
    "            draw.text(position, word_variation, fill=gray_text_color, font=font)\n",
    "\n",
    "            # Add grayscale noise\n",
    "            add_gray_noise(draw, width, height)\n",
    "\n",
    "            # Save image\n",
    "            img.save(os.path.join(\"content/dataset/grayhard\", f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_grayhard_set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with 80:10:10 split\n",
      "Training samples: 16000\n",
      "Validation samples: 2000\n",
      "Test samples: 2000\n",
      "Epoch [1/20], Loss: 3.6940, Train Acc: 14.96%, Val Acc: 39.00%\n",
      "Epoch [2/20], Loss: 2.1567, Train Acc: 47.82%, Val Acc: 51.40%\n",
      "Epoch [3/20], Loss: 1.7127, Train Acc: 58.29%, Val Acc: 60.45%\n",
      "Epoch [4/20], Loss: 1.4756, Train Acc: 63.88%, Val Acc: 58.95%\n",
      "Epoch [5/20], Loss: 1.3108, Train Acc: 67.85%, Val Acc: 68.95%\n",
      "Epoch [6/20], Loss: 1.0753, Train Acc: 73.92%, Val Acc: 72.85%\n",
      "Epoch [7/20], Loss: 0.9985, Train Acc: 75.67%, Val Acc: 73.75%\n",
      "Epoch [8/20], Loss: 0.9678, Train Acc: 76.72%, Val Acc: 74.80%\n",
      "Epoch [9/20], Loss: 0.9327, Train Acc: 77.38%, Val Acc: 75.15%\n",
      "Epoch [10/20], Loss: 0.9081, Train Acc: 78.04%, Val Acc: 75.65%\n",
      "Epoch [11/20], Loss: 0.8605, Train Acc: 79.20%, Val Acc: 75.30%\n",
      "Epoch [12/20], Loss: 0.8617, Train Acc: 78.93%, Val Acc: 73.90%\n",
      "Epoch [13/20], Loss: 0.8532, Train Acc: 79.13%, Val Acc: 75.20%\n",
      "Epoch [14/20], Loss: 0.8474, Train Acc: 79.59%, Val Acc: 75.60%\n",
      "Epoch [15/20], Loss: 0.8495, Train Acc: 79.36%, Val Acc: 75.55%\n",
      "Epoch [16/20], Loss: 0.8433, Train Acc: 79.73%, Val Acc: 75.75%\n",
      "Epoch [17/20], Loss: 0.8471, Train Acc: 79.29%, Val Acc: 76.50%\n",
      "Epoch [18/20], Loss: 0.8383, Train Acc: 79.66%, Val Acc: 74.70%\n",
      "Epoch [19/20], Loss: 0.8462, Train Acc: 79.49%, Val Acc: 74.30%\n",
      "Epoch [20/20], Loss: 0.8428, Train Acc: 79.44%, Val Acc: 76.55%\n",
      "\n",
      "Final Results:\n",
      "Best Validation Accuracy: 76.55%\n",
      "Test Accuracy: 75.15%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# Define the WordCNN class with grayscale input support\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Grayscale input (1 channel)\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.label_to_idx = {word: idx for idx, word in enumerate(set(f.split('_')[0] for f in self.image_files))}\n",
    "        self.idx_to_label = {idx: word for word, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "        label = self.image_files[idx].split('_')[0]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Final test evaluation\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return best_val_acc, test_acc\n",
    "\n",
    "# Testing loop with different activation functions and dropout rates\n",
    "def test_loop():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Data transforms with augmentation (Grayscale only)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),  # Converts to (1, H, W) for grayscale\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single-channel normalization\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = WordImageDataset('content/dataset/grayhard', transform=transform)\n",
    "\n",
    "    # First split: 80% train, 20% temp\n",
    "    train_indices, temp_indices = train_test_split(\n",
    "        range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Second split: Split the temp into validation (10%) and test (10%)\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create subsets\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    print(f\"\\nTesting with 80:10:10 split\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=nn.ReLU(), dropout_rate=0.2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    best_val_acc, test_acc = train_model(\n",
    "        model, train_loader, val_loader, test_loader, \n",
    "        criterion, optimizer, scheduler, num_epochs=20, device=device\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a weird result contradicting our hypothesis. However on further investigation, the loss of accuracy can be attributed to:\n",
    "\n",
    "1. Loss of Color Information\n",
    "    - Many images contain essential features in color escpecially the text having the same color but in grayscale, it is harder to differentiate between the text and the noise. Removal of the color channel information, reduces accuracyy as it is important for distinguishing between noise and text.\n",
    "2. Reduced Feature Space\n",
    "    - Color images (RGB) have three channels, meaning the model gets three different views of the same image. Grayscale images have only one channel, reducing the amount of information available to learn meaningful patterns.\n",
    "3. Weaker Edge Detection\n",
    "    - CNNs often learn to detect edges and textures early in the network, and color can play a crucial role in detecting these edges. When converted to grayscale, color-based contrast and edge information is lost.\n",
    "\n",
    "Lets test one more theory where we fix the text color to be black instead of varying. This will help us understand the true effect (positive/negative) on classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gray_noise(draw, width, height):\n",
    "    for _ in range(random.randint(4000, 5000)):\n",
    "        x, y = random.randint(0, width - 1), random.randint(0, height - 1)\n",
    "        gray_value = random.randint(0, 255)  # Single grayscale intensity\n",
    "        draw.point((x, y), fill=gray_value)\n",
    "\n",
    "if os.path.exists(\"content/dataset/grayhardblacktext\"):\n",
    "    shutil.rmtree(\"content/dataset/grayhardblacktext\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/grayhardblacktext\"):\n",
    "    os.makedirs(\"content/dataset/grayhardblacktext\")\n",
    "\n",
    "def generate_grayhardblacktext_set():\n",
    "    for i in range(0,200):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            img = Image.new(\"L\", (width, height), color=255)  # \"L\" mode for grayscale\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # Generate fonts with random selection\n",
    "            font = ImageFont.truetype(random.choice(FONTS), size=30)\n",
    "            \n",
    "            # Grayscale text color (single intensity for R, G, and B)\n",
    "            gray_text_color = 0\n",
    "            \n",
    "            # Generate random capitalization\n",
    "            word_variation = ''.join(random.choice([c.upper(), c.lower()]) for c in word)\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            position = ((width - text_width) // 2, (height - text_height) // 2)\n",
    "\n",
    "            draw.text(position, word_variation, fill=gray_text_color, font=font)\n",
    "\n",
    "            # Add grayscale noise\n",
    "            add_gray_noise(draw, width, height)\n",
    "\n",
    "            # Save image\n",
    "            img.save(os.path.join(\"content/dataset/grayhardblacktext\", f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_grayhardblacktext_set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with 80:10:10 split\n",
      "Training samples: 16000\n",
      "Validation samples: 2000\n",
      "Test samples: 2000\n",
      "Epoch [1/20], Loss: 3.9995, Train Acc: 9.51%, Val Acc: 30.65%\n",
      "Epoch [2/20], Loss: 2.3559, Train Acc: 43.01%, Val Acc: 49.30%\n",
      "Epoch [3/20], Loss: 1.7935, Train Acc: 55.86%, Val Acc: 60.55%\n",
      "Epoch [4/20], Loss: 1.5340, Train Acc: 62.74%, Val Acc: 62.65%\n",
      "Epoch [5/20], Loss: 1.3563, Train Acc: 66.79%, Val Acc: 64.40%\n",
      "Epoch [6/20], Loss: 1.1029, Train Acc: 73.16%, Val Acc: 72.60%\n",
      "Epoch [7/20], Loss: 1.0263, Train Acc: 75.08%, Val Acc: 73.15%\n",
      "Epoch [8/20], Loss: 0.9965, Train Acc: 75.86%, Val Acc: 73.30%\n",
      "Epoch [9/20], Loss: 0.9652, Train Acc: 76.41%, Val Acc: 73.75%\n",
      "Epoch [10/20], Loss: 0.9273, Train Acc: 77.51%, Val Acc: 74.95%\n",
      "Epoch [11/20], Loss: 0.9010, Train Acc: 78.26%, Val Acc: 75.20%\n",
      "Epoch [12/20], Loss: 0.8944, Train Acc: 78.05%, Val Acc: 75.10%\n",
      "Epoch [13/20], Loss: 0.8889, Train Acc: 78.36%, Val Acc: 74.75%\n",
      "Epoch [14/20], Loss: 0.8939, Train Acc: 77.94%, Val Acc: 75.05%\n",
      "Epoch [15/20], Loss: 0.8871, Train Acc: 78.28%, Val Acc: 75.95%\n",
      "Epoch [16/20], Loss: 0.8778, Train Acc: 78.49%, Val Acc: 75.15%\n",
      "Epoch [17/20], Loss: 0.8832, Train Acc: 78.51%, Val Acc: 75.00%\n",
      "Epoch [18/20], Loss: 0.8789, Train Acc: 78.47%, Val Acc: 76.60%\n",
      "Epoch [19/20], Loss: 0.8819, Train Acc: 78.80%, Val Acc: 75.40%\n",
      "Epoch [20/20], Loss: 0.8842, Train Acc: 78.51%, Val Acc: 75.65%\n",
      "\n",
      "Final Results:\n",
      "Best Validation Accuracy: 76.60%\n",
      "Test Accuracy: 74.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# Define the WordCNN class with grayscale input support\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Grayscale input (1 channel)\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.label_to_idx = {word: idx for idx, word in enumerate(set(f.split('_')[0] for f in self.image_files))}\n",
    "        self.idx_to_label = {idx: word for word, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "        label = self.image_files[idx].split('_')[0]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Final test evaluation\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return best_val_acc, test_acc\n",
    "\n",
    "# Testing loop with different activation functions and dropout rates\n",
    "def test_loop():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Data transforms with augmentation (Grayscale only)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),  # Converts to (1, H, W) for grayscale\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Single-channel normalization\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = WordImageDataset('content/dataset/grayhard', transform=transform)\n",
    "\n",
    "    # First split: 80% train, 20% temp\n",
    "    train_indices, temp_indices = train_test_split(\n",
    "        range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Second split: Split the temp into validation (10%) and test (10%)\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create subsets\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    print(f\"\\nTesting with 80:10:10 split\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=nn.ReLU(), dropout_rate=0.2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    best_val_acc, test_acc = train_model(\n",
    "        model, train_loader, val_loader, test_loader, \n",
    "        criterion, optimizer, scheduler, num_epochs=20, device=device\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did not seem to work. Thus color is an important feature for classification as even after making the text black, the model is still having issues in detecting and classifying the test correctly. Finally lets see what happens when we train the model on a combined dataset of easy to hard in a 2:3 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"content/dataset/combined\"):\n",
    "    shutil.rmtree(\"content/dataset/combined\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/combined\"):\n",
    "    os.makedirs(\"content/dataset/combined\")\n",
    "\n",
    "def generate_combined_set():\n",
    "    for i in range(0,167):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            # generate image with white only\n",
    "            img = Image.new(\"RGB\", (width, height), color=\"white\")\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # generate fonts with random fonts and colors\n",
    "            font = ImageFont.truetype(random.choice(FONTS), size = 30)\n",
    "            text_color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "            \n",
    "            # generate fonts with random capitalization\n",
    "            word_variation = ''.join(random.choice([c.upper(), c.lower()]) for c in word)\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            position = ((width - text_width) // 2, (height - text_height) // 2)\n",
    "\n",
    "            draw.text(position, word_variation, fill=text_color, font=font)\n",
    "\n",
    "            # Add noise\n",
    "            add_noise(draw, width, height)\n",
    "\n",
    "            img.save(os.path.join(\"content/dataset/combined\", f\"{word}_{i}.png\"))\n",
    "    font_path = \"Fonts/OpenSans-Regular.ttf\"\n",
    "    for i in range(167,200):\n",
    "        for word in words:\n",
    "            width, height = 250, 80\n",
    "            color = (255, 255, 255)\n",
    "            image = Image.new(\"RGB\", (width, height), color)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            try:\n",
    "                font = ImageFont.truetype(font_path, 36)\n",
    "            except OSError as e:\n",
    "                print(f\"Error loading font: {e}\")\n",
    "                return\n",
    "            text = word.title()\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "            x = random.randint((width - text_width)//8, 7*((width - text_width)//8))\n",
    "            y = random.randint((height - text_height)//8, 7*((height - text_height)//8))\n",
    "            position = (x,y)\n",
    "            text_color = (0, 0, 0)\n",
    "            draw.text(position, text, font=font, fill=text_color)\n",
    "            image.save(os.path.join(\"content/dataset/combined\", f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_combined_set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with 80:10:10 split\n",
      "Training samples: 16000\n",
      "Validation samples: 2000\n",
      "Test samples: 2000\n",
      "Epoch [1/20], Loss: 4.0784, Train Acc: 7.36%, Val Acc: 17.35%\n",
      "Epoch [2/20], Loss: 2.5464, Train Acc: 37.41%, Val Acc: 47.60%\n",
      "Epoch [3/20], Loss: 1.8283, Train Acc: 54.16%, Val Acc: 49.60%\n",
      "Epoch [4/20], Loss: 1.4340, Train Acc: 63.01%, Val Acc: 61.90%\n",
      "Epoch [5/20], Loss: 1.1781, Train Acc: 68.79%, Val Acc: 69.25%\n",
      "Epoch [6/20], Loss: 0.8409, Train Acc: 78.35%, Val Acc: 77.25%\n",
      "Epoch [7/20], Loss: 0.7549, Train Acc: 80.11%, Val Acc: 78.95%\n",
      "Epoch [8/20], Loss: 0.7042, Train Acc: 81.74%, Val Acc: 80.65%\n",
      "Epoch [9/20], Loss: 0.6689, Train Acc: 82.47%, Val Acc: 81.50%\n",
      "Epoch [10/20], Loss: 0.6251, Train Acc: 83.89%, Val Acc: 81.80%\n",
      "Epoch [11/20], Loss: 0.5904, Train Acc: 84.28%, Val Acc: 82.10%\n",
      "Epoch [12/20], Loss: 0.5710, Train Acc: 85.06%, Val Acc: 82.20%\n",
      "Epoch [13/20], Loss: 0.5770, Train Acc: 84.99%, Val Acc: 82.20%\n",
      "Epoch [14/20], Loss: 0.5790, Train Acc: 84.99%, Val Acc: 83.00%\n",
      "Epoch [15/20], Loss: 0.5801, Train Acc: 84.89%, Val Acc: 82.60%\n",
      "Epoch [16/20], Loss: 0.5603, Train Acc: 85.76%, Val Acc: 82.85%\n",
      "Epoch [17/20], Loss: 0.5600, Train Acc: 85.37%, Val Acc: 82.60%\n",
      "Epoch [18/20], Loss: 0.5579, Train Acc: 85.74%, Val Acc: 82.70%\n",
      "Epoch [19/20], Loss: 0.5549, Train Acc: 85.66%, Val Acc: 82.60%\n",
      "Epoch [20/20], Loss: 0.5549, Train Acc: 85.76%, Val Acc: 81.55%\n",
      "\n",
      "Final Results:\n",
      "Best Validation Accuracy: 83.00%\n",
      "Test Accuracy: 80.45%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# Define the WordCNN class with customizable activation and dropout\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.label_to_idx = {word: idx for idx, word in enumerate(set(f.split('_')[0] for f in self.image_files))}\n",
    "        self.idx_to_label = {idx: word for word, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "        label = self.image_files[idx].split('_')[0]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Final test evaluation\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return best_val_acc, test_acc\n",
    "\n",
    "# Testing loop with different activation functions and dropout rates\n",
    "def test_loop():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Data transforms with augmentation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = WordImageDataset('content/dataset/combined', transform=transform)\n",
    "\n",
    "    # First split: 80% train, 20% temp\n",
    "    train_indices, temp_indices = train_test_split(\n",
    "        range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Second split: Split the temp into validation (10%) and test (10%)\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create subsets\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    print(f\"\\nTesting with 80:10:10 split\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=nn.ReLU(), dropout_rate=0.2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    best_val_acc, test_acc = train_model(\n",
    "        model, train_loader, val_loader, test_loader, \n",
    "        criterion, optimizer, scheduler, num_epochs=20, device=device\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model on this combined dataset worsened the accuracy. Why?\n",
    "- Increased Variability in the Dataset\n",
    "    - First 167 images per word  Random fonts, colors, capitalization, and noise.\n",
    "    - Last 33 images per word  Fixed font (OpenSans-Regular.ttf), black text on a white background, and random text positioning.\n",
    "- Different Text Positioning in the Second Set\n",
    "    - In the second part (images 167200), you are randomizing text positions within (x, y).\n",
    "    - However, in the first 167 images, the text is centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Bonus Set\n",
    "The bonus set has the same features as the hard set with the added complexity of different color backgrounds and text generation.\n",
    "- Images with green background have the text in the normal order of left ro right\n",
    "- Images with red background have the text in reversed order of right to left.\n",
    "- The images have only black text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"content/dataset/bonus\"):\n",
    "    shutil.rmtree(\"content/dataset/bonus\")\n",
    "\n",
    "if not os.path.exists(\"content/dataset\"):\n",
    "    os.makedirs(\"content/dataset\")\n",
    "if not os.path.exists(\"content/dataset/bonus\"):\n",
    "    os.makedirs(\"content/dataset/bonus\")\n",
    "\n",
    "\n",
    "def generate_bonus_set():\n",
    "    for i in range(0, 200):\n",
    "        for word in words:\n",
    "            width, height = 248, 80\n",
    "            bg_color = random.randint(0, 1)\n",
    "            if bg_color == 0 :\n",
    "                bg = \"green\"\n",
    "            else :\n",
    "                bg = \"red\"\n",
    "\n",
    "            img = Image.new(\"RGB\", (width, height), color=bg)\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            font = ImageFont.truetype(random.choice(FONTS), size=30)\n",
    "            text_color = \"black\"\n",
    "\n",
    "            word_variation = ''.join(random.choice([c.upper(), c.lower()]) for c in word)\n",
    "            text_bbox = font.getbbox(word)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            position = ((width - text_width) // 2, (height - text_height) // 2)\n",
    "\n",
    "            if bg_color == 1:\n",
    "                final_word = word_variation [::-1]\n",
    "            else :\n",
    "                final_word = word_variation\n",
    "\n",
    "            draw.text(position, final_word, fill=text_color, font=font)\n",
    "\n",
    "            # Add noise\n",
    "            add_noise(draw, width, height)\n",
    "\n",
    "            img.save(os.path.join(\"content/dataset/bonus\", f\"{word}_{i}.png\"))\n",
    "\n",
    "generate_bonus_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.9239, Train Acc: 8.12%, Val Acc: 21.35%\n",
      "Epoch [2/20], Loss: 1.9339, Train Acc: 48.26%, Val Acc: 57.35%\n",
      "Epoch [3/20], Loss: 1.1295, Train Acc: 68.33%, Val Acc: 75.35%\n",
      "Epoch [4/20], Loss: 0.7937, Train Acc: 76.68%, Val Acc: 80.00%\n",
      "Epoch [5/20], Loss: 0.5889, Train Acc: 82.54%, Val Acc: 87.75%\n",
      "Epoch [6/20], Loss: 0.3537, Train Acc: 90.02%, Val Acc: 92.55%\n",
      "Epoch [7/20], Loss: 0.2938, Train Acc: 91.95%, Val Acc: 92.85%\n",
      "Epoch [8/20], Loss: 0.2692, Train Acc: 92.47%, Val Acc: 93.65%\n",
      "Epoch [9/20], Loss: 0.2397, Train Acc: 93.44%, Val Acc: 94.70%\n",
      "Epoch [10/20], Loss: 0.2241, Train Acc: 94.01%, Val Acc: 94.95%\n",
      "Epoch [11/20], Loss: 0.2085, Train Acc: 94.29%, Val Acc: 95.05%\n",
      "Epoch [12/20], Loss: 0.1988, Train Acc: 94.66%, Val Acc: 95.15%\n",
      "Epoch [13/20], Loss: 0.2017, Train Acc: 94.57%, Val Acc: 95.85%\n",
      "Epoch [14/20], Loss: 0.1931, Train Acc: 94.90%, Val Acc: 95.65%\n",
      "Epoch [15/20], Loss: 0.1951, Train Acc: 94.86%, Val Acc: 95.20%\n",
      "Epoch [16/20], Loss: 0.1935, Train Acc: 94.88%, Val Acc: 95.35%\n",
      "Epoch [17/20], Loss: 0.1921, Train Acc: 94.92%, Val Acc: 95.15%\n",
      "Epoch [18/20], Loss: 0.1834, Train Acc: 95.14%, Val Acc: 95.35%\n",
      "Epoch [19/20], Loss: 0.1922, Train Acc: 94.78%, Val Acc: 95.00%\n",
      "Epoch [20/20], Loss: 0.1941, Train Acc: 94.76%, Val Acc: 95.75%\n",
      "\n",
      "Final Results:\n",
      "Best Validation Accuracy: 95.85%\n",
      "Test Accuracy: 95.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_fn=nn.ReLU(), dropout_rate=0.4):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation_fn,\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128 * 31 * 10, 512),\n",
    "            activation_fn,\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class WordImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.label_to_idx = {word: idx for idx, word in enumerate(set(f.split('_')[0] for f in self.image_files))}\n",
    "        self.idx_to_label = {idx: word for word, idx in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.image_files[idx].split('_')[0]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10, device='cuda'):\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    return best_val_acc, test_acc\n",
    "\n",
    "def test_loop():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((248, 80)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    dataset = WordImageDataset('content/dataset/bonus', transform=transform)\n",
    "    train_indices, temp_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "    val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    model = WordCNN(num_classes=len(dataset.label_to_idx), activation_fn=nn.ReLU(), dropout_rate=0.2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    best_val_acc, test_acc = train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the same code on bonus set results in a similar (or in this speciific case better) accuracy which can be attributed to \n",
    "1. The bonus set has a background that is either green or red, while the hard set always has a white background. Since text color in the bonus set is always black, the contrast between text and background is high, making it easier for the CNN to distinguish characters. In contrast, the hard set uses random text colors on a white background, which can sometimes result in lower contrast (e.g., light-colored text on white), making character recognition harder.\n",
    "2. CNNs can learn to handle predictable transformations (like reversing text) which does not have a negative effect in classification.\n",
    "3. Both datasets add random noise, but in the hard set, the combination of random text colors and random noise makes feature extraction more difficult. In the bonus set, even with noise, the black text remains highly visible due to strong contrast.\n",
    "4. In the hard set, the text color changes along with the font, adding more complexity. The CNN has to learn both color variation and font variation at the same time, making it harder to generalize."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
